{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO4UNfiDIQrwOdd94hwBNjH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nikgup6/DataThon_Team_3/blob/main/DataThon_31Columns.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QoH6TbXR2-DJ",
        "outputId": "968408f4-c385-44dd-d2a0-48bc9a56e676"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Dataset Shape: (49, 131)\n",
            "üîç Missing Value Percentage (Non-Zero Only):\n",
            "Number of Exits                                  100.000000\n",
            "Diversity Spotlight (US Headquarters Only)       100.000000\n",
            "Headquarters Regions                             100.000000\n",
            "Number of Private Contacts                       100.000000\n",
            "Number of Private Notes                          100.000000\n",
            "IPqwery - Most Popular Patent Class              100.000000\n",
            "Actively Hiring                                  100.000000\n",
            "Number of Exits (IPO)                            100.000000\n",
            "Accelerator Duration (in weeks)                  100.000000\n",
            "Accelerator Application Deadline                 100.000000\n",
            "Accelerator Program Type                         100.000000\n",
            "School Type                                      100.000000\n",
            "School Program                                   100.000000\n",
            "Number of Enrollments                            100.000000\n",
            "School Method                                    100.000000\n",
            "Number of Founders (Alumni)                      100.000000\n",
            "Last Leadership Hiring Date                      100.000000\n",
            "Last Layoff Mention Date                         100.000000\n",
            "CB Rank (School)                                 100.000000\n",
            "Delisted Date Precision                          100.000000\n",
            "Money Raised at IPO                              100.000000\n",
            "Money Raised at IPO Currency                     100.000000\n",
            "Money Raised at IPO Currency (in USD)            100.000000\n",
            "Valuation at IPO                                 100.000000\n",
            "Valuation at IPO Currency                        100.000000\n",
            "Valuation at IPO Currency (in USD)               100.000000\n",
            "Stock Symbol                                     100.000000\n",
            "Stock Symbol URL                                 100.000000\n",
            "Stock Exchange                                   100.000000\n",
            "Price                                            100.000000\n",
            "Price Currency                                   100.000000\n",
            "Delisted Date                                    100.000000\n",
            "IPO Date                                         100.000000\n",
            "Price Currency (in USD)                          100.000000\n",
            "Acquisition Terms                                100.000000\n",
            "Tags                                             100.000000\n",
            "Aberdeen - IT Spend Currency (in USD)            100.000000\n",
            "Aberdeen - IT Spend Currency                     100.000000\n",
            "Aberdeen - IT Spend                              100.000000\n",
            "Number of Investments                             97.959184\n",
            "Number of Portfolio Organizations                 97.959184\n",
            "Investor Type                                     97.959184\n",
            "Number of Acquisitions                            97.959184\n",
            "Number of Lead Investments                        97.959184\n",
            "Hub Tags                                          97.959184\n",
            "Closed Date                                       97.959184\n",
            "Number of Diversity Investments                   97.959184\n",
            "Investment Stage                                  97.959184\n",
            "IPqwery - Patents Granted                         95.918367\n",
            "IPqwery - Trademarks Registered                   95.918367\n",
            "IPqwery - Most Popular Trademark Class            95.918367\n",
            "Announced Date                                    93.877551\n",
            "Acquisition Type                                  93.877551\n",
            "Announced Date Precision                          93.877551\n",
            "Transaction Name                                  93.877551\n",
            "Acquired by URL                                   93.877551\n",
            "Exit Date                                         93.877551\n",
            "Exit Date Precision                               93.877551\n",
            "Number of Lead Investors                          93.877551\n",
            "Acquired by                                       93.877551\n",
            "Transaction Name URL                              93.877551\n",
            "Acquisition Status                                91.836735\n",
            "Closed Date Precision                             91.836735\n",
            "Contact Job Departments                           89.795918\n",
            "Number of Contacts                                89.795918\n",
            "Estimated Revenue Range                           83.673469\n",
            "Last Equity Funding Amount                        81.632653\n",
            "Last Equity Funding Amount Currency (in USD)      81.632653\n",
            "Last Equity Funding Amount Currency               81.632653\n",
            "Top 5 Investors                                   79.591837\n",
            "Number of Investors                               79.591837\n",
            "Apptopia - Downloads Last 30 Days                 77.551020\n",
            "Number of Events                                  77.551020\n",
            "Total Equity Funding Amount Currency (in USD)     77.551020\n",
            "Funding Status                                    77.551020\n",
            "Total Equity Funding Amount                       77.551020\n",
            "Last Funding Amount Currency                      75.510204\n",
            "Last Funding Amount                               75.510204\n",
            "Last Equity Funding Type                          75.510204\n",
            "Total Equity Funding Amount Currency              75.510204\n",
            "Last Funding Amount Currency (in USD)             75.510204\n",
            "G2 Stack - Total Products Active                  75.510204\n",
            "Apptopia - Number of Apps                         75.510204\n",
            "Total Funding Amount                              71.428571\n",
            "Total Funding Amount Currency (in USD)            71.428571\n",
            "Number of Funding Rounds                          69.387755\n",
            "Last Funding Date                                 69.387755\n",
            "Total Funding Amount Currency                     69.387755\n",
            "Last Funding Type                                 69.387755\n",
            "SEMrush - Average Visits (6 months)               65.306122\n",
            "Number of Articles                                61.224490\n",
            "SEMrush - Bounce Rate Growth                      59.183673\n",
            "SEMrush - Visit Duration Growth                   59.183673\n",
            "Phone Number                                      59.183673\n",
            "SEMrush - Monthly Rank Change (#)                 53.061224\n",
            "SEMrush - Monthly Visits Growth                   53.061224\n",
            "SEMrush - Monthly Rank Growth                     53.061224\n",
            "SEMrush - Page Views / Visit Growth               53.061224\n",
            "Twitter                                           48.979592\n",
            "SEMrush - Monthly Visits                          46.938776\n",
            "SEMrush - Bounce Rate                             46.938776\n",
            "SEMrush - Visit Duration                          46.938776\n",
            "SEMrush - Global Traffic Rank                     46.938776\n",
            "SEMrush - Page Views / Visit                      46.938776\n",
            "Founders                                          38.775510\n",
            "Number of Founders                                38.775510\n",
            "BuiltWith - Active Tech Count                     22.448980\n",
            "Facebook                                          20.408163\n",
            "Contact Email                                     16.326531\n",
            "Full Description                                  16.326531\n",
            "LinkedIn                                          12.244898\n",
            "Similar Companies                                  6.122449\n",
            "Industry Groups                                    6.122449\n",
            "Industries                                         6.122449\n",
            "Company Type                                       4.081633\n",
            "Number of Employees                                2.040816\n",
            "dtype: float64\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Step 1.1: Load dataset\n",
        "file_path = '/content/Armenia.csv'\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Step 1.2: Show shape\n",
        "print(f\"‚úÖ Dataset Shape: {df.shape}\")\n",
        "\n",
        "# Step 1.3: Calculate missing percentage\n",
        "missing_percent = df.isnull().mean().sort_values(ascending=False) * 100\n",
        "missing_percent = missing_percent[missing_percent > 0]\n",
        "\n",
        "# Display missing percentage\n",
        "pd.set_option('display.max_rows', 150)\n",
        "print(\"üîç Missing Value Percentage (Non-Zero Only):\")\n",
        "print(missing_percent)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ‚úÖ Step 2.1: Select 31 core columns based on the hackathon PDF/docx guidance\n",
        "important_columns = [\n",
        "    \"Founded Date\", \"Number of Founders\", \"Company Type\", \"Number of Employees\",\n",
        "    \"Industries\", \"Headquarters Location\", \"Headquarters Regions\", \"Number of Investors\",\n",
        "    \"Actively Hiring\", \"Number of Funding Rounds\", \"Last Funding Amount\",\n",
        "    \"Funding Status\", \"Last Funding Type\", \"Estimated Revenue Range\", \"IPqwery - Patents Granted\",\n",
        "    \"SEMrush - Monthly Visits\", \"SEMrush - Visit Duration\", \"SEMrush - Page Views / Visit\",\n",
        "    \"SEMrush - Bounce Rate\", \"Number of Events\", \"BuiltWith - Active Tech Count\",\n",
        "    \"G2 Stack - Total Products Active\", \"Number of Articles\", \"CB Rank (Company)\",\n",
        "    \"Total Funding Amount\", \"Valuation at IPO\", \"Price\", \"Number of Exits\",\n",
        "    \"Industry Groups\", \"Apptopia - Downloads Last 30 Days\", \"Apptopia - Number of Apps\"\n",
        "]\n",
        "\n",
        "# Subset the dataframe\n",
        "df_cleaned = df[important_columns].copy()\n",
        "\n",
        "# Save to a new CSV working file\n",
        "df_cleaned.to_csv('/content/Canada_cleaned.csv', index=False)\n",
        "print(\"‚úÖ Created working file: /content/Canada_cleaned.csv with 31 key columns\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W0aHe90P3sUw",
        "outputId": "b5bedda3-1682-4e3a-d801-78367d421424"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Created working file: /content/Canada_cleaned.csv with 31 key columns\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3.1: Fix CB Rank (Company) format\n",
        "df_cleaned[\"CB Rank (Company)\"] = df_cleaned[\"CB Rank (Company)\"].astype(str).str.replace(\",\", \"\")\n",
        "df_cleaned[\"CB Rank (Company)\"] = pd.to_numeric(df_cleaned[\"CB Rank (Company)\"], errors='coerce')\n",
        "\n",
        "# Now fill missing values\n",
        "print(\"Before:\", df_cleaned['CB Rank (Company)'].isnull().sum())\n",
        "\n",
        "# Grouped median by industry (if applicable)\n",
        "if 'Industries' in df_cleaned.columns:\n",
        "    df_cleaned['CB Rank (Company)'] = df_cleaned.groupby('Industries')[\"CB Rank (Company)\"].transform(\n",
        "        lambda x: x.fillna(x.median())\n",
        "    )\n",
        "\n",
        "# Fallback to global median\n",
        "df_cleaned[\"CB Rank (Company)\"] = df_cleaned[\"CB Rank (Company)\"].fillna(df_cleaned[\"CB Rank (Company)\"].median())\n",
        "\n",
        "print(\"After:\", df_cleaned['CB Rank (Company)'].isnull().sum())\n",
        "\n",
        "# Save updated file\n",
        "df_cleaned.to_csv('/content/Canada_cleaned.csv', index=False)\n",
        "print(\"‚úÖ CB Rank (Company) cleaned and imputed.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k8U8E2zm4W98",
        "outputId": "ab201b3d-130e-4fc2-ce8a-33f384600c29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before: 0\n",
            "After: 0\n",
            "‚úÖ CB Rank (Company) cleaned and imputed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if 'Founded Year' exists in the original dataset\n",
        "if 'Founded Year' in df.columns:\n",
        "    print(\"‚úÖ 'Founded Year' exists. Using it to fill missing 'Founded Date'\")\n",
        "\n",
        "    # Convert 'Founded Date' to datetime\n",
        "    df_cleaned['Founded Date'] = pd.to_datetime(df_cleaned['Founded Date'], errors='coerce')\n",
        "\n",
        "    # Use 'Founded Year' to fill missing 'Founded Date'\n",
        "    df_cleaned['Founded Date'] = df_cleaned['Founded Date'].fillna(\n",
        "        pd.to_datetime(df['Founded Year'], errors='coerce')\n",
        "    )\n",
        "\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è 'Founded Year' not found. Will impute using group-wise median\")\n",
        "\n",
        "    # Convert 'Founded Date' to datetime\n",
        "    df_cleaned['Founded Date'] = pd.to_datetime(df_cleaned['Founded Date'], errors='coerce')\n",
        "\n",
        "    # Grouped median fill by Industry\n",
        "    df_cleaned['Founded Date'] = df_cleaned.groupby('Industries')['Founded Date'].transform(\n",
        "        lambda x: x.fillna(x.median())\n",
        "    )\n",
        "\n",
        "# Final fallback to global median\n",
        "df_cleaned['Founded Date'] = df_cleaned['Founded Date'].fillna(df_cleaned['Founded Date'].median())\n",
        "\n",
        "# Check result\n",
        "print(\"‚úÖ Founded Date Missing After Imputation:\", df_cleaned['Founded Date'].isnull().sum())\n",
        "\n",
        "# Save update\n",
        "df_cleaned.to_csv('/content/Canada_cleaned.csv', index=False)\n",
        "print(\"‚úÖ Founded Date imputed and saved.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ccoDMIiw40Na",
        "outputId": "8024ee80-1cd2-4dac-8870-43d2e4bd8688"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚ö†Ô∏è 'Founded Year' not found. Will impute using group-wise median\n",
            "‚úÖ Founded Date Missing After Imputation: 0\n",
            "‚úÖ Founded Date imputed and saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3.3: Impute Company Type\n",
        "\n",
        "print(\"Before:\", df_cleaned[\"Company Type\"].isnull().sum())\n",
        "\n",
        "# Mode per industry group\n",
        "df_cleaned[\"Company Type\"] = df_cleaned.groupby(\"Industries\")[\"Company Type\"].transform(\n",
        "    lambda x: x.fillna(x.mode().iloc[0]) if not x.mode().empty else x\n",
        ")\n",
        "\n",
        "# Fallback global mode\n",
        "global_mode = df_cleaned[\"Company Type\"].mode().iloc[0]\n",
        "df_cleaned[\"Company Type\"] = df_cleaned[\"Company Type\"].fillna(global_mode)\n",
        "\n",
        "print(\"After:\", df_cleaned[\"Company Type\"].isnull().sum())\n",
        "\n",
        "# Save changes\n",
        "df_cleaned.to_csv('/content/Canada_cleaned.csv', index=False)\n",
        "print(\"‚úÖ Company Type imputed and saved.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CluXUcP95EzI",
        "outputId": "98819198-c8ea-4e22-a9ec-53aa0441af5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before: 2\n",
            "After: 0\n",
            "‚úÖ Company Type imputed and saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3.4: Impute Industries\n",
        "print(\"Before:\", df_cleaned[\"Industries\"].isnull().sum())\n",
        "\n",
        "# Group-based mode (by Company Type)\n",
        "df_cleaned[\"Industries\"] = df_cleaned.groupby(\"Company Type\")[\"Industries\"].transform(\n",
        "    lambda x: x.fillna(x.mode().iloc[0]) if not x.mode().empty else x\n",
        ")\n",
        "\n",
        "# Fallback to global mode if still missing\n",
        "global_mode = df_cleaned[\"Industries\"].mode().iloc[0]\n",
        "df_cleaned[\"Industries\"] = df_cleaned[\"Industries\"].fillna(global_mode)\n",
        "\n",
        "print(\"After:\", df_cleaned[\"Industries\"].isnull().sum())\n",
        "\n",
        "# Save update\n",
        "df_cleaned.to_csv('/content/Canada_cleaned.csv', index=False)\n",
        "print(\"‚úÖ Industries imputed and saved.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pgJBD1995MF9",
        "outputId": "8fc2065e-f5d3-4660-f822-f4759fc7be2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before: 3\n",
            "After: 0\n",
            "‚úÖ Industries imputed and saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Step A: Clean \"Number of Employees\"\n",
        "def parse_employees(val):\n",
        "    try:\n",
        "        val = str(val)\n",
        "        if \"-\" in val:\n",
        "            a, b = val.split(\"-\")\n",
        "            return (int(a.replace(\",\", \"\")) + int(b.replace(\",\", \"\"))) // 2\n",
        "        elif val.isdigit():\n",
        "            return int(val)\n",
        "        else:\n",
        "            return np.nan\n",
        "    except:\n",
        "        return np.nan\n",
        "\n",
        "df_cleaned[\"Number of Employees\"] = df_cleaned[\"Number of Employees\"].apply(parse_employees)\n",
        "\n",
        "# Step B: ML Imputation\n",
        "features = [\n",
        "    \"Estimated Revenue Range\", \"SEMrush - Monthly Visits\",\n",
        "    \"CB Rank (Company)\", \"Industries\", \"Funding Status\"\n",
        "]\n",
        "\n",
        "train_df = df_cleaned[df_cleaned[\"Number of Employees\"].notnull()].copy()\n",
        "test_df = df_cleaned[df_cleaned[\"Number of Employees\"].isnull()].copy()\n",
        "\n",
        "# Encode categorical features\n",
        "encoder = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
        "train_encoded = train_df[features].copy()\n",
        "test_encoded = test_df[features].copy()\n",
        "\n",
        "for col in train_encoded.columns:\n",
        "    if train_encoded[col].dtype == \"object\":\n",
        "        train_encoded[col] = train_encoded[col].astype(str)\n",
        "        test_encoded[col] = test_encoded[col].astype(str)\n",
        "\n",
        "encoder.fit(train_encoded)\n",
        "X_train = encoder.transform(train_encoded)\n",
        "X_test = encoder.transform(test_encoded)\n",
        "\n",
        "y_train = train_df[\"Number of Employees\"]\n",
        "\n",
        "# Train model\n",
        "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict missing values\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Fill in predictions\n",
        "df_cleaned.loc[df_cleaned[\"Number of Employees\"].isnull(), \"Number of Employees\"] = y_pred.astype(int)\n",
        "\n",
        "# Save\n",
        "print(\"‚úÖ Missing After:\", df_cleaned[\"Number of Employees\"].isnull().sum())\n",
        "df_cleaned.to_csv('/content/Canada_cleaned.csv', index=False)\n",
        "print(\"‚úÖ Number of Employees imputed with RandomForest and saved.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U-hcjrIn5T-D",
        "outputId": "181b7d35-6c3c-4756-df4f-45d3d8f23b00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Missing After: 0\n",
            "‚úÖ Number of Employees imputed with RandomForest and saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Clean numeric columns with commas\n",
        "numeric_fix_cols = [\"Last Funding Amount\", \"SEMrush - Monthly Visits\", \"SEMrush - Visit Duration\"]\n",
        "\n",
        "for col in numeric_fix_cols:\n",
        "    df_cleaned[col] = df_cleaned[col].astype(str).str.replace(\",\", \"\")\n",
        "    df_cleaned[col] = pd.to_numeric(df_cleaned[col], errors='coerce')\n"
      ],
      "metadata": {
        "id": "UhlIzyGY6vJH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"üß™ Unique values in Estimated Revenue Range (non-null):\")\n",
        "print(df_cleaned[\"Estimated Revenue Range\"].dropna().unique())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YWI6PYDJ63tJ",
        "outputId": "655b2b86-accf-4a04-bbd7-f874825ab924"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üß™ Unique values in Estimated Revenue Range (non-null):\n",
            "['$1M to $10M' 'Less than $1M' '$1B to $10B' '$50M to $100M']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# === Step 0: Clean any comma-based numeric columns ===\n",
        "numeric_fix_cols = [\"Last Funding Amount\", \"SEMrush - Monthly Visits\", \"SEMrush - Visit Duration\"]\n",
        "\n",
        "for col in numeric_fix_cols:\n",
        "    df_cleaned[col] = df_cleaned[col].astype(str).str.replace(\",\", \"\")\n",
        "    df_cleaned[col] = pd.to_numeric(df_cleaned[col], errors='coerce')\n",
        "\n",
        "# === Step 1: Define usable rows and clean unexpected labels ===\n",
        "target_col = \"Estimated Revenue Range\"\n",
        "\n",
        "# Define expected ordered labels\n",
        "ordered_labels = [\n",
        "    \"Less than $1M\", \"$1M to $10M\", \"$10M to $50M\",\n",
        "    \"$50M to $100M\", \"$100M to $500M\", \"$500M to $1B\", \"$1B+\"\n",
        "]\n",
        "\n",
        "# Map all large values into final \"catch-all\" label\n",
        "df_cleaned[target_col] = df_cleaned[target_col].replace({\n",
        "    \"$1B to $10B\": \"$1B+\",\n",
        "    \"$10B+\": \"$1B+\"\n",
        "}).str.strip()\n",
        "\n",
        "# Filter training and test sets\n",
        "train_df = df_cleaned[df_cleaned[target_col].isin(ordered_labels)].copy()\n",
        "test_df = df_cleaned[df_cleaned[target_col].isnull()].copy()\n",
        "\n",
        "# === Step 2: Label encode the target ===\n",
        "label_mapping = {label: idx for idx, label in enumerate(ordered_labels)}\n",
        "inv_label_map = {v: k for k, v in label_mapping.items()}\n",
        "\n",
        "train_df[target_col] = train_df[target_col].map(label_mapping)\n",
        "\n",
        "# === Step 3: Define features and encode them ===\n",
        "features = [\n",
        "    \"Number of Employees\", \"CB Rank (Company)\", \"Funding Status\",\n",
        "    \"Last Funding Amount\", \"SEMrush - Monthly Visits\", \"SEMrush - Visit Duration\",\n",
        "    \"Industries\"\n",
        "]\n",
        "\n",
        "cat_features = [\"Funding Status\", \"Industries\"]\n",
        "encoder = OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=-1)\n",
        "\n",
        "# Encode categorical features\n",
        "X_train = train_df[features].copy()\n",
        "X_test = test_df[features].copy()\n",
        "\n",
        "for col in cat_features:\n",
        "    X_train[col] = X_train[col].astype(str)\n",
        "    X_test[col] = X_test[col].astype(str)\n",
        "\n",
        "encoder.fit(X_train[cat_features])\n",
        "X_train[cat_features] = encoder.transform(X_train[cat_features])\n",
        "X_test[cat_features] = encoder.transform(X_test[cat_features])\n",
        "\n",
        "# === Step 4: Train the classifier ===\n",
        "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "clf.fit(X_train, train_df[target_col])\n",
        "\n",
        "# === Step 5: Predict and map back to original labels ===\n",
        "y_pred = clf.predict(X_test)\n",
        "y_pred_labels = [inv_label_map[int(p)] for p in y_pred]\n",
        "\n",
        "# Fill the predicted labels into df_cleaned\n",
        "df_cleaned.loc[df_cleaned[target_col].isnull(), target_col] = y_pred_labels\n",
        "\n",
        "# === Step 6: Save updated file ===\n",
        "print(\"‚úÖ Estimated Revenue Range missing after:\", df_cleaned[target_col].isnull().sum())\n",
        "df_cleaned.to_csv('/content/Canada_cleaned.csv', index=False)\n",
        "print(\"‚úÖ Estimated Revenue Range imputed and saved.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "532U2aQ05dKA",
        "outputId": "d1de4183-d4b4-46ab-850e-2df3a491e2df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Estimated Revenue Range missing after: 0\n",
            "‚úÖ Estimated Revenue Range imputed and saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# === Step A: Clean commas and convert to float ===\n",
        "df_cleaned[\"Last Funding Amount\"] = df_cleaned[\"Last Funding Amount\"].astype(str).str.replace(\",\", \"\")\n",
        "df_cleaned[\"Last Funding Amount\"] = pd.to_numeric(df_cleaned[\"Last Funding Amount\"], errors='coerce')\n",
        "\n",
        "# === Step B: Prepare training and test sets ===\n",
        "target_col = \"Last Funding Amount\"\n",
        "\n",
        "# Split based on availability\n",
        "train_df = df_cleaned[df_cleaned[target_col].notnull()].copy()\n",
        "test_df = df_cleaned[df_cleaned[target_col].isnull()].copy()\n",
        "\n",
        "# Features to use\n",
        "features = [\n",
        "    \"Estimated Revenue Range\", \"Number of Employees\", \"CB Rank (Company)\",\n",
        "    \"Industries\", \"Funding Status\"\n",
        "]\n",
        "\n",
        "cat_features = [\"Estimated Revenue Range\", \"Industries\", \"Funding Status\"]\n",
        "\n",
        "# Encode categorical columns\n",
        "X_train = train_df[features].copy()\n",
        "X_test = test_df[features].copy()\n",
        "\n",
        "# Convert all categorical to string\n",
        "for col in cat_features:\n",
        "    X_train[col] = X_train[col].astype(str)\n",
        "    X_test[col] = X_test[col].astype(str)\n",
        "\n",
        "# Ordinal encoding for categorical features\n",
        "encoder = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
        "encoder.fit(X_train[cat_features])\n",
        "X_train[cat_features] = encoder.transform(X_train[cat_features])\n",
        "X_test[cat_features] = encoder.transform(X_test[cat_features])\n",
        "\n",
        "# Target variable\n",
        "y_train = train_df[target_col]\n",
        "\n",
        "# === Step C: Train the model ===\n",
        "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# === Step D: Predict missing values ===\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Fill in predictions\n",
        "df_cleaned.loc[df_cleaned[target_col].isnull(), target_col] = y_pred\n",
        "\n",
        "# Save updated file\n",
        "print(\"‚úÖ Last Funding Amount missing after:\", df_cleaned[target_col].isnull().sum())\n",
        "df_cleaned.to_csv('/content/Canada_cleaned.csv', index=False)\n",
        "print(\"‚úÖ Last Funding Amount imputed and saved.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TR4KkE6K6dXN",
        "outputId": "970805a6-7190-4ec1-b73b-265854bfd460"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Last Funding Amount missing after: 0\n",
            "‚úÖ Last Funding Amount imputed and saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"üß™ Unique values in 'Funding Status' (non-null):\")\n",
        "print(df_cleaned[\"Funding Status\"].dropna().unique())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RLTcF8ww7kF9",
        "outputId": "6f7c54e6-4ad3-44e4-ecf3-89ee14d35a08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üß™ Unique values in 'Funding Status' (non-null):\n",
            "['M&A' 'Seed' 'Early Stage Venture']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "\n",
        "# === Step A: Target column ===\n",
        "target_col = \"Funding Status\"\n",
        "\n",
        "# Train/test split\n",
        "train_df = df_cleaned[df_cleaned[target_col].notnull()].copy()\n",
        "test_df = df_cleaned[df_cleaned[target_col].isnull()].copy()\n",
        "\n",
        "# Features used (already cleaned/imputed)\n",
        "features = [\n",
        "    \"Estimated Revenue Range\", \"Last Funding Amount\", \"CB Rank (Company)\",\n",
        "    \"Number of Employees\", \"Industries\"\n",
        "]\n",
        "\n",
        "cat_features = [\"Estimated Revenue Range\", \"Industries\"]\n",
        "\n",
        "# Convert categoricals to string\n",
        "X_train = train_df[features].copy()\n",
        "X_test = test_df[features].copy()\n",
        "for col in cat_features:\n",
        "    X_train[col] = X_train[col].astype(str)\n",
        "    X_test[col] = X_test[col].astype(str)\n",
        "\n",
        "# Ordinal encode categoricals\n",
        "encoder = OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=-1)\n",
        "encoder.fit(X_train[cat_features])\n",
        "X_train[cat_features] = encoder.transform(X_train[cat_features])\n",
        "X_test[cat_features] = encoder.transform(X_test[cat_features])\n",
        "\n",
        "# Prepare target\n",
        "y_train = train_df[target_col].astype(str)\n",
        "\n",
        "# === Step B: Train the model ===\n",
        "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# === Step C: Predict and fill ===\n",
        "y_pred = clf.predict(X_test)\n",
        "df_cleaned.loc[df_cleaned[target_col].isnull(), target_col] = y_pred\n",
        "\n",
        "# Save file\n",
        "print(\"‚úÖ Funding Status missing after:\", df_cleaned[target_col].isnull().sum())\n",
        "df_cleaned.to_csv('/content/Canada_cleaned.csv', index=False)\n",
        "print(\"‚úÖ Funding Status imputed and saved.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rY8rsVhh8HQl",
        "outputId": "d99a7397-4130-49e8-84c9-78da14d6356c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Funding Status missing after: 0\n",
            "‚úÖ Funding Status imputed and saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "\n",
        "# === Step A: Clean column (remove commas if any) ===\n",
        "df_cleaned[\"Total Funding Amount\"] = df_cleaned[\"Total Funding Amount\"].astype(str).str.replace(\",\", \"\")\n",
        "df_cleaned[\"Total Funding Amount\"] = pd.to_numeric(df_cleaned[\"Total Funding Amount\"], errors='coerce')\n",
        "\n",
        "# === Step B: Train/test split ===\n",
        "target_col = \"Total Funding Amount\"\n",
        "train_df = df_cleaned[df_cleaned[target_col].notnull()].copy()\n",
        "test_df = df_cleaned[df_cleaned[target_col].isnull()].copy()\n",
        "\n",
        "# === Step C: Features for prediction ===\n",
        "features = [\n",
        "    \"Last Funding Amount\", \"Estimated Revenue Range\", \"Number of Employees\",\n",
        "    \"CB Rank (Company)\", \"Industries\", \"Funding Status\"\n",
        "]\n",
        "cat_features = [\"Estimated Revenue Range\", \"Industries\", \"Funding Status\"]\n",
        "\n",
        "# === Step D: Encode categorical features ===\n",
        "X_train = train_df[features].copy()\n",
        "X_test = test_df[features].copy()\n",
        "\n",
        "for col in cat_features:\n",
        "    X_train[col] = X_train[col].astype(str)\n",
        "    X_test[col] = X_test[col].astype(str)\n",
        "\n",
        "encoder = OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=-1)\n",
        "encoder.fit(X_train[cat_features])\n",
        "\n",
        "X_train[cat_features] = encoder.transform(X_train[cat_features])\n",
        "X_test[cat_features] = encoder.transform(X_test[cat_features])\n",
        "\n",
        "y_train = train_df[target_col]\n",
        "\n",
        "# === Step E: Train model ===\n",
        "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# === Step F: Predict and fill ===\n",
        "y_pred = model.predict(X_test)\n",
        "df_cleaned.loc[df_cleaned[target_col].isnull(), target_col] = y_pred\n",
        "\n",
        "# === Step G: Save file ===\n",
        "print(\"‚úÖ Total Funding Amount missing after:\", df_cleaned[target_col].isnull().sum())\n",
        "df_cleaned.to_csv('/content/Canada_cleaned.csv', index=False)\n",
        "print(\"‚úÖ Total Funding Amount imputed and saved.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5NCDxEUh8blx",
        "outputId": "08eaf88b-b692-439d-bb1b-166b1ff54be0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Total Funding Amount missing after: 0\n",
            "‚úÖ Total Funding Amount imputed and saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "\n",
        "# === Step A: Clean Valuation column ===\n",
        "target_col = \"Valuation at IPO\"\n",
        "df_cleaned[target_col] = df_cleaned[target_col].astype(str).str.replace(\",\", \"\")\n",
        "df_cleaned[target_col] = pd.to_numeric(df_cleaned[target_col], errors='coerce')\n",
        "\n",
        "# === Step B: Focus only on IPO companies ===\n",
        "ipo_df = df_cleaned[df_cleaned[\"Funding Status\"] == \"IPO\"].copy()\n",
        "\n",
        "# Train/test split (within IPO rows only)\n",
        "train_df = ipo_df[ipo_df[target_col].notnull()].copy()\n",
        "test_df = ipo_df[ipo_df[target_col].isnull()].copy()\n",
        "\n",
        "# If very few rows exist with actual values, just skip\n",
        "if len(train_df) < 10:\n",
        "    print(\"‚ö†Ô∏è Not enough IPO rows with real valuations. Skipping imputation.\")\n",
        "else:\n",
        "    # === Step C: Define features ===\n",
        "    features = [\n",
        "        \"Total Funding Amount\", \"Last Funding Amount\", \"Estimated Revenue Range\",\n",
        "        \"CB Rank (Company)\", \"Number of Employees\", \"Industries\"\n",
        "    ]\n",
        "    cat_features = [\"Estimated Revenue Range\", \"Industries\"]\n",
        "\n",
        "    X_train = train_df[features].copy()\n",
        "    X_test = test_df[features].copy()\n",
        "\n",
        "    for col in cat_features:\n",
        "        X_train[col] = X_train[col].astype(str)\n",
        "        X_test[col] = X_test[col].astype(str)\n",
        "\n",
        "    encoder = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
        "    encoder.fit(X_train[cat_features])\n",
        "    X_train[cat_features] = encoder.transform(X_train[cat_features])\n",
        "    X_test[cat_features] = encoder.transform(X_test[cat_features])\n",
        "\n",
        "    y_train = train_df[target_col]\n",
        "\n",
        "    # === Step D: Train model ===\n",
        "    model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # === Step E: Predict and insert ===\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    df_cleaned.loc[test_df.index, target_col] = y_pred\n",
        "\n",
        "    # Save file\n",
        "    print(\"‚úÖ Valuation at IPO missing after:\", df_cleaned[target_col].isnull().sum())\n",
        "    df_cleaned.to_csv('/content/Canada_cleaned.csv', index=False)\n",
        "    print(\"‚úÖ Valuation at IPO imputed and saved (only for IPO-tagged startups).\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MPlY2-pTLdfV",
        "outputId": "3e853a12-d1dc-48eb-b9aa-eabd81287a8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚ö†Ô∏è Not enough IPO rows with real valuations. Skipping imputation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load cleaned file\n",
        "df_cleaned = pd.read_csv('/content/Canada_cleaned.csv')\n",
        "\n",
        "# Summary\n",
        "print(\"‚úÖ Shape:\", df_cleaned.shape)\n",
        "print(\"\\nüìâ Missing Values (%):\")\n",
        "print(df_cleaned.isnull().mean().sort_values(ascending=False) * 100)\n",
        "\n",
        "# Show sample rows\n",
        "df_cleaned.head()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "y1OoUsx4Loni",
        "outputId": "641fa322-0d29-46f8-e38e-ed83891a4c36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Shape: (49, 31)\n",
            "\n",
            "üìâ Missing Values (%):\n",
            "Headquarters Regions                 100.000000\n",
            "Actively Hiring                      100.000000\n",
            "Valuation at IPO                     100.000000\n",
            "Number of Exits                      100.000000\n",
            "Price                                100.000000\n",
            "IPqwery - Patents Granted             95.918367\n",
            "Number of Investors                   79.591837\n",
            "Number of Events                      77.551020\n",
            "Apptopia - Downloads Last 30 Days     77.551020\n",
            "G2 Stack - Total Products Active      75.510204\n",
            "Apptopia - Number of Apps             75.510204\n",
            "Last Funding Type                     69.387755\n",
            "Number of Funding Rounds              69.387755\n",
            "Number of Articles                    61.224490\n",
            "SEMrush - Monthly Visits              46.938776\n",
            "SEMrush - Page Views / Visit          46.938776\n",
            "SEMrush - Visit Duration              46.938776\n",
            "SEMrush - Bounce Rate                 46.938776\n",
            "Number of Founders                    38.775510\n",
            "BuiltWith - Active Tech Count         22.448980\n",
            "Industry Groups                        6.122449\n",
            "Industries                             0.000000\n",
            "Headquarters Location                  0.000000\n",
            "Estimated Revenue Range                0.000000\n",
            "Funding Status                         0.000000\n",
            "Last Funding Amount                    0.000000\n",
            "Founded Date                           0.000000\n",
            "Company Type                           0.000000\n",
            "Number of Employees                    0.000000\n",
            "CB Rank (Company)                      0.000000\n",
            "Total Funding Amount                   0.000000\n",
            "dtype: float64\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          Founded Date  Number of Founders Company Type  Number of Employees  \\\n",
              "0  2017-01-01 00:00:00                 NaN   For Profit                 30.0   \n",
              "1  2016-01-01 00:00:00                 1.0   For Profit                 30.0   \n",
              "2  2022-04-25 00:00:00                 1.0   For Profit                  5.0   \n",
              "3  2014-01-18 00:00:00                 1.0   For Profit                 75.0   \n",
              "4  2023-05-02 00:00:00                 NaN   For Profit                  5.0   \n",
              "\n",
              "                                          Industries  \\\n",
              "0  Information Technology, Mobile Apps, Software,...   \n",
              "1  E-Commerce, FinTech, Information Technology, S...   \n",
              "2      Advertising, Marketing, Professional Services   \n",
              "3                   Information Technology, Software   \n",
              "4  Blockchain, Cryptocurrency, Gamification, Gami...   \n",
              "\n",
              "       Headquarters Location  Headquarters Regions  Number of Investors  \\\n",
              "0  Yerevan, Yerevan, Armenia                   NaN                  NaN   \n",
              "1  Yerevan, Yerevan, Armenia                   NaN                  NaN   \n",
              "2  Yerevan, Yerevan, Armenia                   NaN                  NaN   \n",
              "3  Yerevan, Yerevan, Armenia                   NaN                  NaN   \n",
              "4  Yerevan, Yerevan, Armenia                   NaN                  NaN   \n",
              "\n",
              "   Actively Hiring  Number of Funding Rounds  ...  \\\n",
              "0              NaN                       NaN  ...   \n",
              "1              NaN                       NaN  ...   \n",
              "2              NaN                       NaN  ...   \n",
              "3              NaN                       NaN  ...   \n",
              "4              NaN                       NaN  ...   \n",
              "\n",
              "   G2 Stack - Total Products Active Number of Articles CB Rank (Company)  \\\n",
              "0                               NaN                NaN         2049738.0   \n",
              "1                               NaN                NaN          784580.0   \n",
              "2                               NaN                NaN          666127.0   \n",
              "3                              18.0               57.0          203866.0   \n",
              "4                               NaN                NaN          373491.0   \n",
              "\n",
              "  Total Funding Amount  Valuation at IPO  Price  Number of Exits  \\\n",
              "0             900013.0               NaN    NaN              NaN   \n",
              "1            6636210.0               NaN    NaN              NaN   \n",
              "2             631109.0               NaN    NaN              NaN   \n",
              "3            7031460.0               NaN    NaN              NaN   \n",
              "4             632239.0               NaN    NaN              NaN   \n",
              "\n",
              "                                     Industry Groups  \\\n",
              "0     Apps, Information Technology, Mobile, Software   \n",
              "1  Commerce and Shopping, Financial Services, Inf...   \n",
              "2            Advertising, Other, Sales and Marketing   \n",
              "3                   Information Technology, Software   \n",
              "4  Financial Services, Gaming, Information Techno...   \n",
              "\n",
              "  Apptopia - Downloads Last 30 Days  Apptopia - Number of Apps  \n",
              "0                               NaN                        NaN  \n",
              "1                               NaN                        NaN  \n",
              "2                               NaN                        NaN  \n",
              "3                                89                      133.0  \n",
              "4                               NaN                        NaN  \n",
              "\n",
              "[5 rows x 31 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-47b0489e-1ba1-44d4-b5a7-40a10a51b8e7\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Founded Date</th>\n",
              "      <th>Number of Founders</th>\n",
              "      <th>Company Type</th>\n",
              "      <th>Number of Employees</th>\n",
              "      <th>Industries</th>\n",
              "      <th>Headquarters Location</th>\n",
              "      <th>Headquarters Regions</th>\n",
              "      <th>Number of Investors</th>\n",
              "      <th>Actively Hiring</th>\n",
              "      <th>Number of Funding Rounds</th>\n",
              "      <th>...</th>\n",
              "      <th>G2 Stack - Total Products Active</th>\n",
              "      <th>Number of Articles</th>\n",
              "      <th>CB Rank (Company)</th>\n",
              "      <th>Total Funding Amount</th>\n",
              "      <th>Valuation at IPO</th>\n",
              "      <th>Price</th>\n",
              "      <th>Number of Exits</th>\n",
              "      <th>Industry Groups</th>\n",
              "      <th>Apptopia - Downloads Last 30 Days</th>\n",
              "      <th>Apptopia - Number of Apps</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2017-01-01 00:00:00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>For Profit</td>\n",
              "      <td>30.0</td>\n",
              "      <td>Information Technology, Mobile Apps, Software,...</td>\n",
              "      <td>Yerevan, Yerevan, Armenia</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2049738.0</td>\n",
              "      <td>900013.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Apps, Information Technology, Mobile, Software</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2016-01-01 00:00:00</td>\n",
              "      <td>1.0</td>\n",
              "      <td>For Profit</td>\n",
              "      <td>30.0</td>\n",
              "      <td>E-Commerce, FinTech, Information Technology, S...</td>\n",
              "      <td>Yerevan, Yerevan, Armenia</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>784580.0</td>\n",
              "      <td>6636210.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Commerce and Shopping, Financial Services, Inf...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2022-04-25 00:00:00</td>\n",
              "      <td>1.0</td>\n",
              "      <td>For Profit</td>\n",
              "      <td>5.0</td>\n",
              "      <td>Advertising, Marketing, Professional Services</td>\n",
              "      <td>Yerevan, Yerevan, Armenia</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>666127.0</td>\n",
              "      <td>631109.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Advertising, Other, Sales and Marketing</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2014-01-18 00:00:00</td>\n",
              "      <td>1.0</td>\n",
              "      <td>For Profit</td>\n",
              "      <td>75.0</td>\n",
              "      <td>Information Technology, Software</td>\n",
              "      <td>Yerevan, Yerevan, Armenia</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>18.0</td>\n",
              "      <td>57.0</td>\n",
              "      <td>203866.0</td>\n",
              "      <td>7031460.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Information Technology, Software</td>\n",
              "      <td>89</td>\n",
              "      <td>133.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2023-05-02 00:00:00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>For Profit</td>\n",
              "      <td>5.0</td>\n",
              "      <td>Blockchain, Cryptocurrency, Gamification, Gami...</td>\n",
              "      <td>Yerevan, Yerevan, Armenia</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>373491.0</td>\n",
              "      <td>632239.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Financial Services, Gaming, Information Techno...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows √ó 31 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-47b0489e-1ba1-44d4-b5a7-40a10a51b8e7')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-47b0489e-1ba1-44d4-b5a7-40a10a51b8e7 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-47b0489e-1ba1-44d4-b5a7-40a10a51b8e7');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-7ead2195-a605-4556-97a3-deb3c64c120d\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7ead2195-a605-4556-97a3-deb3c64c120d')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-7ead2195-a605-4556-97a3-deb3c64c120d button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_cleaned"
            }
          },
          "metadata": {},
          "execution_count": 562
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "col = \"Industry Groups\"\n",
        "\n",
        "# A. Basic info\n",
        "print(f\"üîç Column: {col}\")\n",
        "print(f\"‚û°Ô∏è Missing: {df_cleaned[col].isnull().sum()} / {len(df_cleaned)}\")\n",
        "print(f\"‚û°Ô∏è Missing %: {df_cleaned[col].isnull().mean()*100:.2f}%\")\n",
        "\n",
        "# B. Unique non-null values\n",
        "print(\"\\nüß™ Unique non-null values:\")\n",
        "print(df_cleaned[col].dropna().unique()[:30])  # show first 30 unique values\n",
        "\n",
        "# C. Value counts (Top 10)\n",
        "print(\"\\nüìä Most common values:\")\n",
        "print(df_cleaned[col].value_counts().head(10))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jTYQ-ch9LokD",
        "outputId": "a4514840-c91e-4cac-fc4a-3f1d6fa2c52b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîç Column: Industry Groups\n",
            "‚û°Ô∏è Missing: 3 / 49\n",
            "‚û°Ô∏è Missing %: 6.12%\n",
            "\n",
            "üß™ Unique non-null values:\n",
            "['Apps, Information Technology, Mobile, Software'\n",
            " 'Commerce and Shopping, Financial Services, Information Technology, Software'\n",
            " 'Advertising, Other, Sales and Marketing'\n",
            " 'Information Technology, Software'\n",
            " 'Financial Services, Gaming, Information Technology, Internet Services, Other, Payments, Software'\n",
            " 'Administrative Services, Education, Professional Services'\n",
            " 'Financial Services, Lending and Investments'\n",
            " 'Education, Information Technology, Software' 'Other, Software'\n",
            " 'Content and Publishing, Information Technology, Media and Entertainment, Sales and Marketing, Software'\n",
            " 'Commerce and Shopping, Information Technology, Software'\n",
            " 'Content and Publishing, Media and Entertainment, Software, Video'\n",
            " 'Advertising, Design, Internet Services, Sales and Marketing, Software'\n",
            " 'Apps, Hardware, Information Technology, Internet Services, Mobile, Platforms, Software'\n",
            " 'Apps, Artificial Intelligence, Data and Analytics, Gaming, Mobile, Science and Engineering, Software'\n",
            " 'Information Technology, Internet Services, Software'\n",
            " 'Financial Services, Other, Payments, Software'\n",
            " 'Gaming, Science and Engineering, Software'\n",
            " 'Clothing and Apparel, Commerce and Shopping, Design, Other'\n",
            " 'Data and Analytics, Information Technology, Other, Software'\n",
            " 'Agriculture and Farming, Software' 'Administrative Services'\n",
            " 'Clothing and Apparel, Consumer Electronics, Design, Hardware'\n",
            " 'Advertising, Sales and Marketing'\n",
            " 'Content and Publishing, Internet Services, Media and Entertainment'\n",
            " 'Administrative Services, Commerce and Shopping, Transportation, Travel and Tourism'\n",
            " 'Health Care, Information Technology, Software'\n",
            " 'Data and Analytics, Media and Entertainment, Professional Services, Software, Video'\n",
            " 'Sales and Marketing'\n",
            " 'Advertising, Agriculture and Farming, Artificial Intelligence, Data and Analytics, Sales and Marketing, Science and Engineering, Software']\n",
            "\n",
            "üìä Most common values:\n",
            "Industry Groups\n",
            "Information Technology, Internet Services, Software                                                       2\n",
            "Commerce and Shopping, Financial Services, Information Technology, Software                               1\n",
            "Advertising, Other, Sales and Marketing                                                                   1\n",
            "Information Technology, Software                                                                          1\n",
            "Apps, Information Technology, Mobile, Software                                                            1\n",
            "Administrative Services, Education, Professional Services                                                 1\n",
            "Financial Services, Lending and Investments                                                               1\n",
            "Education, Information Technology, Software                                                               1\n",
            "Other, Software                                                                                           1\n",
            "Content and Publishing, Information Technology, Media and Entertainment, Sales and Marketing, Software    1\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "# Only fill nulls using mode per 'Industries'\n",
        "def fill_by_grouped_mode(df, target_col, group_col):\n",
        "    df[target_col] = df.groupby(group_col)[target_col].transform(\n",
        "        lambda x: x.fillna(x.mode().iloc[0]) if not x.mode().empty else x\n",
        "    )\n",
        "    return df\n",
        "\n",
        "# Apply\n",
        "df_cleaned = fill_by_grouped_mode(df_cleaned, \"Industry Groups\", \"Industries\")\n",
        "\n",
        "# Confirm\n",
        "print(\"‚úÖ Missing after imputation:\", df_cleaned[\"Industry Groups\"].isnull().sum())\n",
        "\n",
        "# Save\n",
        "df_cleaned.to_csv(\"/content/Canada_cleaned.csv\", index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rcFGxlqiLohk",
        "outputId": "97e632fd-9090-42ef-ca05-6bde2b5f627c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Missing after imputation: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "\n",
        "# Step A: Setup\n",
        "target_col = \"BuiltWith - Active Tech Count\"\n",
        "features = [\n",
        "    \"Number of Employees\", \"Total Funding Amount\",\n",
        "    \"Estimated Revenue Range\", \"Industry Groups\"\n",
        "]\n",
        "\n",
        "# Step B: Prepare a shared encoder for both train and test\n",
        "encoder = OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=-1)\n",
        "\n",
        "# Combine for encoding\n",
        "non_null_rows = df_cleaned.dropna(subset=features)\n",
        "encoder.fit(non_null_rows[[\"Estimated Revenue Range\", \"Industry Groups\"]])\n",
        "\n",
        "# Encode both train and predict parts\n",
        "df_encoded = df_cleaned.copy()\n",
        "df_encoded[[\"Estimated Revenue Range\", \"Industry Groups\"]] = encoder.transform(\n",
        "    df_encoded[[\"Estimated Revenue Range\", \"Industry Groups\"]]\n",
        ")\n",
        "\n",
        "# Step C: Train the model\n",
        "train_df = df_encoded.dropna(subset=features + [target_col])\n",
        "X_train = train_df[features]\n",
        "y_train = train_df[target_col]\n",
        "\n",
        "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Step D: Predict and fill\n",
        "pred_df = df_encoded[df_cleaned[target_col].isnull()]\n",
        "X_pred = pred_df[features]\n",
        "y_pred = model.predict(X_pred)\n",
        "\n",
        "# Fill values into original dataframe\n",
        "df_cleaned.loc[df_cleaned[target_col].isnull(), target_col] = y_pred\n",
        "\n",
        "# Step E: Save\n",
        "print(\"‚úÖ Missing after imputation:\", df_cleaned[target_col].isnull().sum())\n",
        "df_cleaned.to_csv(\"/content/Canada_cleaned.csv\", index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "izuxM0XlLoe8",
        "outputId": "aea9696e-796c-449c-ed81-2e7fa4d12140"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Missing after imputation: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "col = \"Number of Founders\"\n",
        "\n",
        "# A. Basic info\n",
        "print(f\"üîç Column: {col}\")\n",
        "print(f\"‚û°Ô∏è Missing: {df_cleaned[col].isnull().sum()} / {len(df_cleaned)}\")\n",
        "print(f\"‚û°Ô∏è Missing %: {df_cleaned[col].isnull().mean()*100:.2f}%\")\n",
        "\n",
        "# B. Unique values (non-null)\n",
        "print(\"\\nüß™ Unique non-null values:\")\n",
        "print(sorted(df_cleaned[col].dropna().unique()))\n",
        "\n",
        "# C. Correlation analysis (optional preview)\n",
        "print(\"\\nüìä Correlation with:\")\n",
        "print(df_cleaned[[col, \"Number of Employees\", \"Total Funding Amount\"]].corr())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tsJaqc3DLoch",
        "outputId": "51c22498-9634-4f58-a5e6-17e02ae38385"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîç Column: Number of Founders\n",
            "‚û°Ô∏è Missing: 19 / 49\n",
            "‚û°Ô∏è Missing %: 38.78%\n",
            "\n",
            "üß™ Unique non-null values:\n",
            "[np.float64(1.0), np.float64(2.0), np.float64(3.0), np.float64(4.0), np.float64(5.0)]\n",
            "\n",
            "üìä Correlation with:\n",
            "                      Number of Founders  Number of Employees  \\\n",
            "Number of Founders              1.000000             0.306291   \n",
            "Number of Employees             0.306291             1.000000   \n",
            "Total Funding Amount           -0.142456             0.088259   \n",
            "\n",
            "                      Total Funding Amount  \n",
            "Number of Founders               -0.142456  \n",
            "Number of Employees               0.088259  \n",
            "Total Funding Amount              1.000000  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "col = \"Number of Founders\"\n",
        "group_cols = [\"Company Type\", \"Industries\"]\n",
        "\n",
        "# Step 1: Group-median logic\n",
        "df_cleaned[col] = df_cleaned.groupby(group_cols)[col].transform(\n",
        "    lambda x: x.fillna(x.median())\n",
        ")\n",
        "\n",
        "# Step 2: If any left, fill with global median\n",
        "df_cleaned[col] = df_cleaned[col].fillna(df_cleaned[col].median())\n",
        "\n",
        "# Step 3: Save\n",
        "print(\"‚úÖ Missing after imputation:\", df_cleaned[col].isnull().sum())\n",
        "df_cleaned.to_csv(\"/content/Canada_cleaned.csv\", index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "syQ9L8dXLoaA",
        "outputId": "1285452b-b01b-4e79-9823-55d8766f778b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Missing after imputation: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Step A: Define a function to extract region\n",
        "def extract_region(location):\n",
        "    if pd.isnull(location): return np.nan\n",
        "    parts = location.split(\",\")\n",
        "    if len(parts) == 3:\n",
        "        return parts[1].strip()  # Extract Province/State\n",
        "    return np.nan\n",
        "\n",
        "# Step B: Apply extraction\n",
        "df_cleaned[\"Extracted Region\"] = df_cleaned[\"Headquarters Location\"].apply(extract_region)\n",
        "\n",
        "# Step C: Fill missing values\n",
        "df_cleaned[\"Headquarters Regions\"] = df_cleaned[\"Headquarters Regions\"].fillna(df_cleaned[\"Extracted Region\"])\n",
        "\n",
        "# Step D: Still missing? Fill with 'Unknown'\n",
        "df_cleaned[\"Headquarters Regions\"] = df_cleaned[\"Headquarters Regions\"].fillna(\"Unknown\")\n",
        "\n",
        "# Step E: Drop helper column\n",
        "df_cleaned.drop(columns=[\"Extracted Region\"], inplace=True)\n",
        "\n",
        "# Step F: Save\n",
        "print(\"‚úÖ Missing after imputation:\", df_cleaned[\"Headquarters Regions\"].isnull().sum())\n",
        "df_cleaned.to_csv(\"/content/Canada_cleaned.csv\", index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fRBKVtizLoXS",
        "outputId": "8c634728-85be-4838-89af-54277f73dd55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Missing after imputation: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "\n",
        "target_col = \"Number of Funding Rounds\"\n",
        "features = [\n",
        "    \"Total Funding Amount\",\n",
        "    \"Last Funding Amount\",\n",
        "    \"Estimated Revenue Range\",\n",
        "    \"Funding Status\",\n",
        "    \"Industries\"\n",
        "]\n",
        "\n",
        "# Step A: Prepare Encoder\n",
        "encoder = OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=-1)\n",
        "df_encoded = df_cleaned.copy()\n",
        "df_encoded[[\"Estimated Revenue Range\", \"Funding Status\", \"Industries\"]] = encoder.fit_transform(\n",
        "    df_encoded[[\"Estimated Revenue Range\", \"Funding Status\", \"Industries\"]]\n",
        ")\n",
        "\n",
        "# Step B: Train model\n",
        "train_df = df_encoded.dropna(subset=features + [target_col])\n",
        "X_train = train_df[features]\n",
        "y_train = train_df[target_col]\n",
        "\n",
        "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Step C: Predict\n",
        "predict_df = df_encoded[df_cleaned[target_col].isnull()]\n",
        "X_pred = predict_df[features]\n",
        "y_pred = model.predict(X_pred)\n",
        "\n",
        "# Step D: Impute\n",
        "df_cleaned.loc[df_cleaned[target_col].isnull(), target_col] = y_pred\n",
        "\n",
        "# Step E: Save\n",
        "print(\"‚úÖ Missing after imputation:\", df_cleaned[target_col].isnull().sum())\n",
        "df_cleaned.to_csv(\"/content/Canada_cleaned.csv\", index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M95GLUt1O1lq",
        "outputId": "5d860f9e-efc0-4e9e-fea4-3aaef2f24017"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Missing after imputation: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_cleaned[\"Last Funding Type\"].dropna().unique())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9lSl1gACPDO8",
        "outputId": "d98edc3e-f481-48ba-c4e5-b8c619a183f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Grant' 'Seed' 'Initial Coin Offering' 'Product Crowdfunding' 'Pre-Seed'\n",
            " 'Venture - Series Unknown' 'Series A' 'Undisclosed' 'Equity Crowdfunding']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "\n",
        "target_col = \"Last Funding Type\"\n",
        "features = [\n",
        "    \"Funding Status\",\n",
        "    \"Estimated Revenue Range\",\n",
        "    \"Total Funding Amount\",\n",
        "    \"Number of Funding Rounds\",\n",
        "    \"Industries\",\n",
        "    \"Last Funding Amount\"\n",
        "]\n",
        "\n",
        "# Step A: Ordinal Encode categorical features\n",
        "encoder = OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=-1)\n",
        "df_encoded = df_cleaned.copy()\n",
        "df_encoded[[\"Funding Status\", \"Estimated Revenue Range\", \"Industries\"]] = encoder.fit_transform(\n",
        "    df_encoded[[\"Funding Status\", \"Estimated Revenue Range\", \"Industries\"]]\n",
        ")\n",
        "\n",
        "# Step B: Label encode the target\n",
        "label_mapping = {label: idx for idx, label in enumerate(df_encoded[target_col].dropna().unique())}\n",
        "inv_label_mapping = {v: k for k, v in label_mapping.items()}\n",
        "df_encoded[target_col] = df_encoded[target_col].map(label_mapping)\n",
        "\n",
        "# Step C: Prepare training and prediction sets\n",
        "train_df = df_encoded.dropna(subset=features + [target_col])\n",
        "X_train = train_df[features]\n",
        "y_train = train_df[target_col]\n",
        "\n",
        "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Predict for missing\n",
        "predict_df = df_encoded[df_cleaned[target_col].isnull()]\n",
        "X_pred = predict_df[features]\n",
        "y_pred = clf.predict(X_pred)\n",
        "\n",
        "# Step D: Impute predicted values\n",
        "predicted_labels = [inv_label_mapping[int(label)] for label in y_pred]\n",
        "df_cleaned.loc[df_cleaned[target_col].isnull(), target_col] = predicted_labels\n",
        "\n",
        "# Step E: Save\n",
        "print(\"‚úÖ Missing after imputation:\", df_cleaned[target_col].isnull().sum())\n",
        "df_cleaned.to_csv(\"/content/Canada_cleaned.csv\", index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4wqAOR5jPMMS",
        "outputId": "8d6d7da1-4249-41ee-cd3d-2af1dc779984"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Missing after imputation: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "\n",
        "target_col = \"SEMrush - Monthly Visits\"\n",
        "features = [\n",
        "    \"Estimated Revenue Range\",\n",
        "    \"Number of Employees\",\n",
        "    \"Industries\",\n",
        "    \"Last Funding Amount\"\n",
        "]\n",
        "\n",
        "# Encode categorical features\n",
        "df_encoded = df_cleaned.copy()\n",
        "encoder = OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=-1)\n",
        "df_encoded[[\"Estimated Revenue Range\", \"Industries\"]] = encoder.fit_transform(\n",
        "    df_encoded[[\"Estimated Revenue Range\", \"Industries\"]]\n",
        ")\n",
        "\n",
        "# Drop rows without any of the features\n",
        "train_df = df_encoded.dropna(subset=features + [target_col])\n",
        "X_train = train_df[features]\n",
        "y_train = train_df[target_col]\n",
        "\n",
        "# Train model\n",
        "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict for missing\n",
        "predict_df = df_encoded[df_cleaned[target_col].isnull()]\n",
        "X_pred = predict_df[features]\n",
        "y_pred = model.predict(X_pred)\n",
        "\n",
        "# Impute values\n",
        "df_cleaned.loc[df_cleaned[target_col].isnull(), target_col] = y_pred\n",
        "\n",
        "# Save and confirm\n",
        "print(\"‚úÖ Missing after imputation:\", df_cleaned[target_col].isnull().sum())\n",
        "df_cleaned.to_csv(\"/content/Canada_cleaned.csv\", index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DrmtPinfPX2y",
        "outputId": "63fd15e8-0b43-44c7-8ebf-8b11486c3ae9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Missing after imputation: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Target column\n",
        "target_col = \"SEMrush - Page Views / Visit\"\n",
        "features = [\n",
        "    \"Estimated Revenue Range\",\n",
        "    \"Industries\",\n",
        "    \"Number of Employees\",\n",
        "    \"SEMrush - Monthly Visits\"\n",
        "]\n",
        "\n",
        "# Encode categorical columns\n",
        "df_encoded = df_cleaned.copy()\n",
        "encoder = OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=-1)\n",
        "df_encoded[[\"Estimated Revenue Range\", \"Industries\"]] = encoder.fit_transform(\n",
        "    df_encoded[[\"Estimated Revenue Range\", \"Industries\"]]\n",
        ")\n",
        "\n",
        "# Drop rows with missing feature or target\n",
        "train_df = df_encoded.dropna(subset=features + [target_col])\n",
        "X_train = train_df[features]\n",
        "y_train = train_df[target_col]\n",
        "\n",
        "# Train model\n",
        "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict missing\n",
        "predict_df = df_encoded[df_cleaned[target_col].isnull()]\n",
        "X_pred = predict_df[features]\n",
        "y_pred = model.predict(X_pred)\n",
        "\n",
        "# Fill missing\n",
        "df_cleaned.loc[df_cleaned[target_col].isnull(), target_col] = y_pred\n",
        "\n",
        "# Save and confirm\n",
        "print(\"‚úÖ Missing after imputation:\", df_cleaned[target_col].isnull().sum())\n",
        "df_cleaned.to_csv(\"/content/Canada_cleaned.csv\", index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h765NcyAPlsH",
        "outputId": "26381a60-2271-4cec-f125-e9394a40b0a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Missing after imputation: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Target\n",
        "target_col = \"SEMrush - Visit Duration\"\n",
        "features = [\n",
        "    \"SEMrush - Page Views / Visit\",\n",
        "    \"SEMrush - Monthly Visits\",\n",
        "    \"Estimated Revenue Range\",\n",
        "    \"Industries\"\n",
        "]\n",
        "\n",
        "# Ordinal encode\n",
        "df_encoded = df_cleaned.copy()\n",
        "encoder = OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=-1)\n",
        "df_encoded[[\"Estimated Revenue Range\", \"Industries\"]] = encoder.fit_transform(\n",
        "    df_encoded[[\"Estimated Revenue Range\", \"Industries\"]]\n",
        ")\n",
        "\n",
        "# Training data\n",
        "train_df = df_encoded.dropna(subset=features + [target_col])\n",
        "X_train = train_df[features]\n",
        "y_train = train_df[target_col]\n",
        "\n",
        "# Model\n",
        "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict missing\n",
        "predict_df = df_encoded[df_cleaned[target_col].isnull()]\n",
        "X_pred = predict_df[features]\n",
        "y_pred = model.predict(X_pred)\n",
        "\n",
        "# Impute\n",
        "df_cleaned.loc[df_cleaned[target_col].isnull(), target_col] = y_pred\n",
        "\n",
        "# Save\n",
        "print(\"‚úÖ Missing after imputation:\", df_cleaned[target_col].isnull().sum())\n",
        "df_cleaned.to_csv(\"/content/Canada_cleaned.csv\", index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VULdjwTLQFA_",
        "outputId": "b32632f1-60cc-4041-afea-5313804024de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Missing after imputation: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Target column\n",
        "target_col = \"SEMrush - Bounce Rate\"\n",
        "\n",
        "# Step A: Preprocess percentage column\n",
        "df_cleaned[target_col] = df_cleaned[target_col].apply(\n",
        "    lambda x: float(str(x).replace('%', '')) if pd.notnull(x) else np.nan\n",
        ")\n",
        "\n",
        "# Features for prediction\n",
        "features = [\n",
        "    \"SEMrush - Visit Duration\",\n",
        "    \"SEMrush - Page Views / Visit\",\n",
        "    \"Estimated Revenue Range\",\n",
        "    \"Industries\"\n",
        "]\n",
        "\n",
        "# Encode categoricals\n",
        "df_encoded = df_cleaned.copy()\n",
        "encoder = OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=-1)\n",
        "df_encoded[[\"Estimated Revenue Range\", \"Industries\"]] = encoder.fit_transform(\n",
        "    df_encoded[[\"Estimated Revenue Range\", \"Industries\"]]\n",
        ")\n",
        "\n",
        "# Train data\n",
        "train_df = df_encoded.dropna(subset=features + [target_col])\n",
        "X_train = train_df[features]\n",
        "y_train = train_df[target_col]\n",
        "\n",
        "# Model\n",
        "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict\n",
        "predict_df = df_encoded[df_cleaned[target_col].isnull()]\n",
        "X_pred = predict_df[features]\n",
        "y_pred = model.predict(X_pred)\n",
        "\n",
        "# Fill\n",
        "df_cleaned.loc[df_cleaned[target_col].isnull(), target_col] = y_pred\n",
        "\n",
        "# Optional: Reconvert to percentage string if needed\n",
        "# df_cleaned[target_col] = df_cleaned[target_col].apply(lambda x: f\"{x:.2f}%\" if pd.notnull(x) else x)\n",
        "\n",
        "# Save\n",
        "print(\"‚úÖ Missing after imputation:\", df_cleaned[target_col].isnull().sum())\n",
        "df_cleaned.to_csv(\"/content/Canada_cleaned.csv\", index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NbvzG5GbQSVa",
        "outputId": "18be9ffb-2724-4cfc-e189-eed6b12e313f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Missing after imputation: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print([col for col in df_cleaned.columns if \"SEMrush\" in col])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZBrEcmNaQ7C2",
        "outputId": "334da9ae-dee9-4f3e-cbf0-d0fe17bde52e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['SEMrush - Monthly Visits', 'SEMrush - Visit Duration', 'SEMrush - Page Views / Visit', 'SEMrush - Bounce Rate']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Target column\n",
        "target_col = \"Apptopia - Downloads Last 30 Days\"\n",
        "\n",
        "# Features\n",
        "features = [\n",
        "    \"Apptopia - Number of Apps\",\n",
        "    \"Estimated Revenue Range\",\n",
        "    \"Industries\",\n",
        "    \"Number of Employees\",\n",
        "    \"Funding Status\"\n",
        "]\n",
        "\n",
        "# Step 1: Encode categoricals\n",
        "df_encoded = df_cleaned.copy()\n",
        "encoder = OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=-1)\n",
        "df_encoded[[\"Estimated Revenue Range\", \"Industries\", \"Funding Status\"]] = encoder.fit_transform(\n",
        "    df_encoded[[\"Estimated Revenue Range\", \"Industries\", \"Funding Status\"]]\n",
        ")\n",
        "\n",
        "# Step 2: Clean target (remove commas, convert to float)\n",
        "df_encoded[target_col] = df_encoded[target_col].astype(str).str.replace(\",\", \"\")\n",
        "df_encoded[target_col] = pd.to_numeric(df_encoded[target_col], errors=\"coerce\")\n",
        "\n",
        "# Step 3: Filter training data\n",
        "train_df = df_encoded.dropna(subset=features + [target_col])\n",
        "X_train = train_df[features]\n",
        "y_train = train_df[target_col]\n",
        "\n",
        "# Step 4: Train model\n",
        "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Step 5: Predict and fill missing values\n",
        "predict_df = df_encoded[df_cleaned[target_col].isnull()]\n",
        "X_pred = predict_df[features]\n",
        "y_pred = model.predict(X_pred)\n",
        "df_cleaned.loc[df_cleaned[target_col].isnull(), target_col] = y_pred\n",
        "\n",
        "# Step 6: Save\n",
        "print(\"‚úÖ Missing after imputation:\", df_cleaned[target_col].isnull().sum())\n",
        "df_cleaned.to_csv(\"/content/Canada_cleaned.csv\", index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RYnU0AV6RA14",
        "outputId": "1d895cf0-b91f-4ca4-f664-575ff629aeb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Missing after imputation: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_cleaned[\"Apptopia - Number of Apps\"].dropna().unique())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ByG4_U4IRZZy",
        "outputId": "25141f82-46d1-48de-8822-5eede9f9ad43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[133.   2.   1.  15.   3.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# üìÇ Copy original cleaned dataset\n",
        "df_encoded = df_cleaned.copy()\n",
        "\n",
        "# üéØ Target column to impute\n",
        "target_col = \"Apptopia - Number of Apps\"\n",
        "\n",
        "# üîç Features to use\n",
        "features = [\n",
        "    \"Estimated Revenue Range\",\n",
        "    \"Industries\",\n",
        "    \"Funding Status\",\n",
        "    \"Apptopia - Downloads Last 30 Days\",\n",
        "    \"Number of Employees\"\n",
        "]\n",
        "\n",
        "# üßº Convert target column to numeric (remove commas, convert to float)\n",
        "df_encoded[target_col] = pd.to_numeric(df_encoded[target_col].astype(str).str.replace(\",\", \"\"), errors='coerce')\n",
        "\n",
        "# üßº Also clean any numeric-looking features if needed\n",
        "df_encoded[\"Apptopia - Downloads Last 30 Days\"] = pd.to_numeric(\n",
        "    df_encoded[\"Apptopia - Downloads Last 30 Days\"].astype(str).str.replace(\",\", \"\"), errors='coerce'\n",
        ")\n",
        "\n",
        "# üõë Filter rows for training\n",
        "train_df = df_encoded.dropna(subset=features + [target_col])\n",
        "predict_df = df_encoded[df_encoded[target_col].isnull()]\n",
        "\n",
        "# üß† Categorical features\n",
        "cat_features = [\"Estimated Revenue Range\", \"Industries\", \"Funding Status\"]\n",
        "\n",
        "# üîß Fill missing and ensure strings\n",
        "for col in cat_features:\n",
        "    train_df.loc[:, col] = train_df[col].astype(str).fillna(\"Unknown\")\n",
        "    predict_df.loc[:, col] = predict_df[col].astype(str).fillna(\"Unknown\")\n",
        "\n",
        "# üß† Encode categorical features\n",
        "encoder = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
        "train_df.loc[:, cat_features] = encoder.fit_transform(train_df[cat_features])\n",
        "predict_df.loc[:, cat_features] = encoder.transform(predict_df[cat_features])\n",
        "\n",
        "# üéØ Prepare training and prediction sets\n",
        "X_train = train_df[features]\n",
        "y_train = train_df[target_col].astype(float)\n",
        "X_pred = predict_df[features]\n",
        "\n",
        "# ü§ñ Train Random Forest Regressor\n",
        "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# üîÆ Predict missing values\n",
        "y_pred = model.predict(X_pred)\n",
        "\n",
        "# üíæ Fill back into main DataFrame\n",
        "df_encoded.loc[df_encoded[target_col].isnull(), target_col] = y_pred\n",
        "\n",
        "# ‚úÖ Update cleaned dataframe\n",
        "df_cleaned[target_col] = df_encoded[target_col]\n",
        "\n",
        "# üíæ Save to CSV\n",
        "df_cleaned.to_csv(\"/content/Canada_cleaned.csv\", index=False)\n",
        "\n",
        "# ‚úÖ Final confirmation\n",
        "print(f\"‚úÖ Missing after imputation: {df_cleaned[target_col].isnull().sum()}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ILGtAdWSRwOC",
        "outputId": "07b055e2-1f15-46b6-82be-b02962c92a6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Missing after imputation: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "import pandas as pd\n",
        "\n",
        "# üõ†Ô∏è Configuration\n",
        "target_col = \"SEMrush - Monthly Visits\"   # change this to your target column\n",
        "cat_features = [\"Industry Groups\", \"Estimated Revenue Range\", \"Funding Status\"]  # adjust as needed\n",
        "\n",
        "# üîç Filter rows for training (non-null target)\n",
        "train_df = df_cleaned[df_cleaned[target_col].notnull()].copy()\n",
        "predict_df = df_cleaned[df_cleaned[target_col].isnull()].copy()\n",
        "\n",
        "# üßº Clean target column (remove %, commas, convert to float)\n",
        "def clean_numeric_col(col):\n",
        "    return (\n",
        "        col.astype(str)\n",
        "           .str.replace(\",\", \"\", regex=False)\n",
        "           .str.replace(\"%\", \"\", regex=False)\n",
        "           .replace(\"nan\", pd.NA)\n",
        "           .astype(float)\n",
        "    )\n",
        "\n",
        "train_df[target_col] = clean_numeric_col(train_df[target_col])\n",
        "df_cleaned[target_col] = clean_numeric_col(df_cleaned[target_col])\n",
        "\n",
        "# üîß Fill missing and convert cat features to string for encoding\n",
        "for col in cat_features:\n",
        "    train_df[col] = train_df[col].astype(str).fillna(\"Unknown\")\n",
        "    predict_df[col] = predict_df[col].astype(str).fillna(\"Unknown\")\n",
        "\n",
        "# üéØ Define features\n",
        "features = cat_features\n",
        "\n",
        "# üî¢ Encode categorical features safely\n",
        "encoder = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
        "train_df.loc[:, cat_features] = encoder.fit_transform(train_df[cat_features])\n",
        "\n",
        "if not predict_df.empty:\n",
        "    predict_df.loc[:, cat_features] = encoder.transform(predict_df[cat_features])\n",
        "\n",
        "# ‚úÖ Model training\n",
        "X_train = train_df[features]\n",
        "y_train = train_df[target_col]\n",
        "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# üîÆ Prediction and imputation\n",
        "if not predict_df.empty:\n",
        "    X_pred = predict_df[features]\n",
        "    y_pred = model.predict(X_pred)\n",
        "    df_cleaned.loc[df_cleaned[target_col].isnull(), target_col] = y_pred\n",
        "\n",
        "# ‚úÖ Final check\n",
        "print(f\"‚úÖ Missing after imputation: {df_cleaned[target_col].isnull().sum()}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cJsxvT8JR4Lj",
        "outputId": "a548e3ab-d8b0-47d6-c6bd-582f3c141fb9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Missing after imputation: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# üßº Check missing values count and percentage\n",
        "missing_info = (\n",
        "    df_cleaned.isnull().sum()\n",
        "    .to_frame(\"Missing Count\")\n",
        "    .assign(\n",
        "        Missing_Percentage=lambda x: (x[\"Missing Count\"] / len(df_cleaned)) * 100\n",
        "    )\n",
        "    .sort_values(by=\"Missing Count\", ascending=False)\n",
        ")\n",
        "\n",
        "# üñ®Ô∏è Show only columns with missing values\n",
        "missing_info = missing_info[missing_info[\"Missing Count\"] > 0]\n",
        "print(missing_info)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cZIO7eQMSXcS",
        "outputId": "8da9ad38-7401-453d-ec5e-309e59f03865"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                  Missing Count  Missing_Percentage\n",
            "Actively Hiring                              49          100.000000\n",
            "Number of Exits                              49          100.000000\n",
            "Valuation at IPO                             49          100.000000\n",
            "Price                                        49          100.000000\n",
            "IPqwery - Patents Granted                    47           95.918367\n",
            "Number of Investors                          39           79.591837\n",
            "Number of Events                             38           77.551020\n",
            "G2 Stack - Total Products Active             37           75.510204\n",
            "Number of Articles                           30           61.224490\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "\n",
        "# üßπ Copy DataFrame to avoid modifying original\n",
        "df_encoded = df_cleaned.copy()\n",
        "\n",
        "# üéØ Target column\n",
        "target_col = \"Number of Articles\"\n",
        "\n",
        "# üß† Features to predict the target\n",
        "features = [\n",
        "    \"Number of Employees\",\n",
        "    \"Total Funding Amount\",\n",
        "    \"Estimated Revenue Range\",\n",
        "    \"Industries\",\n",
        "    \"Funding Status\",\n",
        "    \"Number of Founders\"\n",
        "]\n",
        "\n",
        "# üßπ Clean target column: remove commas and convert to float\n",
        "df_encoded[target_col] = df_encoded[target_col].astype(str).str.replace(\",\", \"\").replace(\"nan\", pd.NA)\n",
        "df_encoded[target_col] = pd.to_numeric(df_encoded[target_col], errors='coerce')\n",
        "\n",
        "# üéØ Drop rows with missing values in features or target (for training)\n",
        "train_df = df_encoded.dropna(subset=features + [target_col])\n",
        "predict_df = df_encoded[df_encoded[target_col].isnull()]\n",
        "\n",
        "# üß† Categorical features\n",
        "cat_features = [col for col in features if df_encoded[col].dtype == 'object']\n",
        "\n",
        "# Step 1: Fill NaNs with 'Unknown' and convert to string for encoding\n",
        "for col in cat_features:\n",
        "    train_df.loc[:, col] = train_df[col].astype(str).fillna('Unknown')\n",
        "    predict_df.loc[:, col] = predict_df[col].astype(str).fillna('Unknown')\n",
        "\n",
        "# Step 2: Ordinal encoding\n",
        "encoder = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
        "train_df.loc[:, cat_features] = encoder.fit_transform(train_df[cat_features])\n",
        "predict_df.loc[:, cat_features] = encoder.transform(predict_df[cat_features])\n",
        "\n",
        "# Step 3: Model training and prediction\n",
        "X_train = train_df[features]\n",
        "y_train = train_df[target_col]\n",
        "X_pred = predict_df[features]\n",
        "\n",
        "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_pred)\n",
        "\n",
        "# Step 4: Fill predicted values\n",
        "df_encoded.loc[df_encoded[target_col].isnull(), target_col] = y_pred\n",
        "\n",
        "# ‚úÖ Update the main cleaned DataFrame\n",
        "df_cleaned[target_col] = df_encoded[target_col]\n",
        "\n",
        "# üíæ Save to CSV\n",
        "df_cleaned.to_csv(\"/content/Canada_cleaned.csv\", index=False)\n",
        "\n",
        "# ‚úÖ Final check\n",
        "print(f\"‚úÖ Missing after imputation: {df_cleaned[target_col].isnull().sum()}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C0tNIZiATeMK",
        "outputId": "113dbb0a-4cc3-4e2d-af0e-f10731764821"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Missing after imputation: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "import numpy as np\n",
        "\n",
        "# ‚úÖ Define target and features (REMOVE the missing column)\n",
        "target_col = \"Number of Investors\"\n",
        "features = [\n",
        "    \"Estimated Revenue Range\",\n",
        "    \"Industries\",\n",
        "    \"Funding Status\",\n",
        "    \"Total Funding Amount\",\n",
        "    \"Number of Funding Rounds\",\n",
        "    \"Last Funding Amount\"\n",
        "]\n",
        "\n",
        "# ‚úÖ Work on a fresh copy\n",
        "df_encoded = df_cleaned.copy()\n",
        "\n",
        "# ‚úÖ Handle numeric strings: remove commas and convert to float\n",
        "for col in [\"Total Funding Amount\", \"Last Funding Amount\"]:\n",
        "    df_encoded[col] = (\n",
        "        df_encoded[col]\n",
        "        .astype(str)\n",
        "        .str.replace(\",\", \"\", regex=False)\n",
        "        .replace(\"Unknown\", np.nan)\n",
        "        .astype(float)\n",
        "    )\n",
        "\n",
        "# ‚úÖ Split training and prediction sets\n",
        "train_df = df_encoded.dropna(subset=features + [target_col])\n",
        "predict_df = df_encoded[df_encoded[target_col].isnull()]\n",
        "\n",
        "# ‚úÖ Identify and encode categorical features\n",
        "cat_features = [\"Estimated Revenue Range\", \"Industries\", \"Funding Status\"]\n",
        "for col in cat_features:\n",
        "    train_df.loc[:, col] = train_df[col].astype(str).fillna(\"Unknown\")\n",
        "    predict_df.loc[:, col] = predict_df[col].astype(str).fillna(\"Unknown\")\n",
        "\n",
        "# ‚úÖ Encode categorical columns\n",
        "encoder = OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=-1)\n",
        "train_df.loc[:, cat_features] = encoder.fit_transform(train_df[cat_features])\n",
        "predict_df.loc[:, cat_features] = encoder.transform(predict_df[cat_features])\n",
        "\n",
        "# ‚úÖ Prepare data for model\n",
        "X_train = train_df[features]\n",
        "y_train = train_df[target_col].astype(float)\n",
        "X_pred = predict_df[features]\n",
        "\n",
        "# ‚úÖ Train model\n",
        "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# ‚úÖ Predict\n",
        "y_pred = model.predict(X_pred)\n",
        "\n",
        "# ‚úÖ Fill predictions back\n",
        "df_encoded.loc[df_encoded[target_col].isnull(), target_col] = y_pred\n",
        "df_cleaned[target_col] = df_encoded[target_col]\n",
        "\n",
        "# ‚úÖ Save file\n",
        "df_cleaned.to_csv(\"/content/Canada_cleaned.csv\", index=False)\n",
        "\n",
        "# ‚úÖ Summary\n",
        "missing_after = df_cleaned[target_col].isnull().sum()\n",
        "print(f\"‚úÖ Missing after imputation: {missing_after}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "94VRfM1RUCvJ",
        "outputId": "e7ab2e32-718b-481b-da85-e8b2e94fc6be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Missing after imputation: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "\n",
        "# üßπ Step 1: Setup\n",
        "df_encoded = df_cleaned.copy()\n",
        "target_col = \"G2 Stack - Total Products Active\"\n",
        "\n",
        "# üß† Step 2: Select features (add/remove based on your domain knowledge)\n",
        "features = [\n",
        "    \"Estimated Revenue Range\",\n",
        "    \"Industries\",\n",
        "    \"Funding Status\",\n",
        "    \"Number of Employees\",\n",
        "    \"Total Funding Amount\",\n",
        "    \"Apptopia - Number of Apps\",\n",
        "    \"Apptopia - Downloads Last 30 Days\"\n",
        "]\n",
        "\n",
        "# üß™ Step 3: Drop rows with missing feature or target for training\n",
        "train_df = df_encoded.dropna(subset=features + [target_col])\n",
        "predict_df = df_encoded[df_encoded[target_col].isnull()]\n",
        "\n",
        "# üßº Step 4: Identify categorical features to encode\n",
        "cat_features = train_df[features].select_dtypes(include='object').columns.tolist()\n",
        "\n",
        "# üí° Step 5: Preprocess categorical values\n",
        "for col in cat_features:\n",
        "    train_df.loc[:, col] = train_df[col].astype(str).fillna('Unknown')\n",
        "    predict_df.loc[:, col] = predict_df[col].astype(str).fillna('Unknown')\n",
        "\n",
        "\n",
        "# üöÄ Step 6: Encode categorical columns\n",
        "encoder = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
        "train_df.loc[:, cat_features] = encoder.fit_transform(train_df[cat_features])\n",
        "predict_df.loc[:, cat_features] = encoder.transform(predict_df[cat_features])\n",
        "\n",
        "\n",
        "# üß† Step 7: Prepare train/predict sets\n",
        "X_train = train_df[features]\n",
        "y_train = train_df[target_col].astype(str).str.replace(\",\", \"\").astype(float)\n",
        "X_pred = predict_df[features]\n",
        "\n",
        "# üèóÔ∏è Step 8: Train model and predict\n",
        "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_pred)\n",
        "\n",
        "# üíæ Step 9: Fill predicted values back into original dataframe\n",
        "df_encoded.loc[df_encoded[target_col].isnull(), target_col] = y_pred\n",
        "df_cleaned[target_col] = df_encoded[target_col]\n",
        "\n",
        "# ‚úÖ Step 10: Confirm\n",
        "print(f\"‚úÖ Missing after imputation: {df_cleaned[target_col].isnull().sum()}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sv8bCqWqVWg9",
        "outputId": "15349213-d2df-4ebe-b60e-d0a661a9458e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Missing after imputation: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "\n",
        "# Load the cleaned data\n",
        "df_cleaned = pd.read_csv('/content/Canada_cleaned.csv')\n",
        "\n",
        "target_col = \"Actively Hiring\"\n",
        "features = [\n",
        "    \"Number of Employees\",\n",
        "    \"Estimated Revenue Range\",\n",
        "    \"Funding Status\",\n",
        "    \"Company Type\"\n",
        "]\n",
        "\n",
        "# Fill NaNs in feature columns temporarily for training\n",
        "for col in features:\n",
        "    if df_cleaned[col].dtype == 'object':\n",
        "        df_cleaned[col] = df_cleaned[col].astype(str).fillna('Unknown')\n",
        "    else:\n",
        "        df_cleaned[col] = df_cleaned[col].fillna(-1)\n",
        "\n",
        "# Split train/predict sets\n",
        "train_df = df_cleaned[df_cleaned[target_col].notnull()].copy()\n",
        "predict_df = df_cleaned[df_cleaned[target_col].isnull()].copy()\n",
        "\n",
        "# If no training data or no prediction data, skip\n",
        "if train_df.empty or predict_df.empty:\n",
        "    print(f\"‚ÑπÔ∏è Skipping {target_col} ‚Äî train or predict set is empty.\")\n",
        "else:\n",
        "    # Identify categorical features\n",
        "    cat_features = [col for col in features if train_df[col].dtype == 'object']\n",
        "\n",
        "    # Encode categorical variables\n",
        "    encoder = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
        "    train_df[cat_features] = encoder.fit_transform(train_df[cat_features])\n",
        "    predict_df[cat_features] = encoder.transform(predict_df[cat_features])\n",
        "\n",
        "    # Train and predict\n",
        "    X_train = train_df[features]\n",
        "    y_train = train_df[target_col]\n",
        "    X_pred = predict_df[features]\n",
        "\n",
        "    model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    y_pred = model.predict(X_pred)\n",
        "\n",
        "    # Update the main DataFrame\n",
        "    df_cleaned.loc[predict_df.index, target_col] = y_pred\n",
        "\n",
        "    print(f\"‚úÖ Missing after imputation for {target_col}: {df_cleaned[target_col].isnull().sum()}\")\n",
        "\n",
        "# Save CSV\n",
        "df_cleaned.to_csv('/content/Canada_cleaned.csv', index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bsUo6pmIWlg4",
        "outputId": "a68bfd9e-7917-4d28-8117-55da7a27c8ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚ÑπÔ∏è Skipping Actively Hiring ‚Äî train or predict set is empty.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "\n",
        "# Load the cleaned data\n",
        "df_cleaned = pd.read_csv('/content/Canada_cleaned.csv')\n",
        "\n",
        "target_col = \"Actively Hiring\"\n",
        "features = [\n",
        "    \"Number of Employees\",\n",
        "    \"Estimated Revenue Range\",\n",
        "    \"Funding Status\",\n",
        "    \"Company Type\"\n",
        "]\n",
        "\n",
        "df_encoded = df_cleaned.copy()\n",
        "\n",
        "# Identify categorical features\n",
        "cat_features = [col for col in features if df_encoded[col].dtype == 'object']\n",
        "\n",
        "# Split train/predict sets\n",
        "train_df = df_encoded.dropna(subset=[target_col]).copy()\n",
        "predict_df = df_encoded[df_encoded[target_col].isnull()].copy()\n",
        "\n",
        "# Only run if both sets have rows\n",
        "if train_df.empty or predict_df.empty:\n",
        "    print(f\"‚ÑπÔ∏è Skipping {target_col} ‚Äî No missing values or no training data.\")\n",
        "else:\n",
        "    # Fill missing feature values before encoding\n",
        "    for col in features:\n",
        "        if col in cat_features:\n",
        "            train_df[col] = train_df[col].astype(str).fillna('Unknown')\n",
        "            predict_df[col] = predict_df[col].astype(str).fillna('Unknown')\n",
        "        else:\n",
        "            train_df[col] = train_df[col].fillna(-1)\n",
        "            predict_df[col] = predict_df[col].fillna(-1)\n",
        "\n",
        "    # Encode categorical variables\n",
        "    encoder = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
        "    train_df[cat_features] = encoder.fit_transform(train_df[cat_features])\n",
        "    predict_df[cat_features] = encoder.transform(predict_df[cat_features])\n",
        "\n",
        "    # Train and predict\n",
        "    X_train = train_df[features]\n",
        "    y_train = train_df[target_col]\n",
        "    X_pred = predict_df[features]\n",
        "\n",
        "    model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    y_pred = model.predict(X_pred)\n",
        "\n",
        "    # Update missing values\n",
        "    df_cleaned.loc[predict_df.index, target_col] = y_pred\n",
        "\n",
        "    print(f\"‚úÖ Missing after imputation for {target_col}: {df_cleaned[target_col].isnull().sum()}\")\n",
        "\n",
        "# Save final CSV\n",
        "df_cleaned.to_csv('/content/Canada_cleaned.csv', index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UD-fkJtAYZi8",
        "outputId": "287df7b2-b083-41f3-f2ee-6d0317456eda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚ÑπÔ∏è Skipping Actively Hiring ‚Äî No missing values or no training data.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "col_name = \"Actively Hiring\"  # change as needed\n",
        "print(f\"Unique count: {df_cleaned[col_name].nunique(dropna=False)}\")\n",
        "print(\"Sample values:\", df_cleaned[col_name].unique())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6q0DciC9uzGd",
        "outputId": "f0962f4b-356f-4730-8e2b-cd0f78f9d655"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique count: 1\n",
            "Sample values: [nan]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "import numpy as np\n",
        "\n",
        "# Load the cleaned data\n",
        "df_cleaned = pd.read_csv('/content/Canada_cleaned.csv')\n",
        "\n",
        "# --- Setup for Imputation ---\n",
        "target_col = \"Price\"\n",
        "features = [\n",
        "    \"Total Funding Amount\",\n",
        "    \"Valuation at IPO\",\n",
        "    \"Number of Employees\",\n",
        "    \"Funding Status\",\n",
        "    \"Industries\"\n",
        "]\n",
        "\n",
        "# Create a copy for encoding\n",
        "df_encoded = df_cleaned.copy()\n",
        "\n",
        "# Filter for rows where a Price might exist (e.g., acquisitions, IPOs)\n",
        "price_relevant_df = df_encoded[df_encoded['Funding Status'].isin(['M&A', 'IPO', 'Private Equity'])].copy()\n",
        "\n",
        "# --- Preprocessing and Encoding ---\n",
        "# Ensure numeric features are floats\n",
        "for col in [\"Total Funding Amount\", \"Valuation at IPO\", \"Number of Employees\"]:\n",
        "    price_relevant_df[col] = pd.to_numeric(price_relevant_df[col], errors='coerce')\n",
        "\n",
        "# Identify categorical features\n",
        "cat_features = [col for col in features if price_relevant_df[col].dtype == 'object']\n",
        "\n",
        "# Split into training and prediction sets within the filtered data\n",
        "train_df = price_relevant_df.dropna(subset=features + [target_col])\n",
        "predict_df = price_relevant_df[price_relevant_df[target_col].isnull()]\n",
        "\n",
        "if len(train_df) < 5:\n",
        "    print(f\"‚ö†Ô∏è Not enough training data for {target_col}. Imputation skipped.\")\n",
        "else:\n",
        "    # Handle 'nan' values in categorical features for encoding\n",
        "    for col in cat_features:\n",
        "        train_df.loc[:, col] = train_df[col].astype(str).fillna('Unknown')\n",
        "        predict_df.loc[:, col] = predict_df[col].astype(str).fillna('Unknown')\n",
        "\n",
        "    # Use OrdinalEncoder to transform categorical features\n",
        "    encoder = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
        "    train_df.loc[:, cat_features] = encoder.fit_transform(train_df[cat_features])\n",
        "    predict_df.loc[:, cat_features] = encoder.transform(predict_df[cat_features])\n",
        "\n",
        "    # --- Train and Predict ---\n",
        "    X_train = train_df[features]\n",
        "    y_train = train_df[target_col]\n",
        "    X_pred = predict_df[features]\n",
        "\n",
        "    model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_pred)\n",
        "\n",
        "    # --- Impute and Save ---\n",
        "    df_cleaned.loc[predict_df.index, target_col] = y_pred\n",
        "\n",
        "# Save the final cleaned dataframe\n",
        "df_cleaned.to_csv('/content/Canada_cleaned.csv', index=False)\n",
        "\n",
        "print(f\"‚úÖ Missing after imputation for {target_col}: {df_cleaned[target_col].isnull().sum()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tzAsJpdUYZfR",
        "outputId": "9e62db9f-8410-4128-a0c5-8f5c1bba22f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚ö†Ô∏è Not enough training data for Price. Imputation skipped.\n",
            "‚úÖ Missing after imputation for Price: 49\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "import numpy as np\n",
        "\n",
        "# Load the cleaned data\n",
        "df_cleaned = pd.read_csv('/content/Canada_cleaned.csv')\n",
        "\n",
        "# --- Setup for Imputation ---\n",
        "target_col = \"Number of Events\"\n",
        "features = [\n",
        "    \"Number of Employees\",\n",
        "    \"Number of Articles\",\n",
        "    \"Number of Funding Rounds\",\n",
        "    \"Estimated Revenue Range\",\n",
        "    \"Industries\"\n",
        "]\n",
        "\n",
        "# Create a copy for encoding\n",
        "df_encoded = df_cleaned.copy()\n",
        "\n",
        "# --- Preprocessing and Encoding ---\n",
        "# Ensure numeric features are floats\n",
        "for col in [\"Number of Employees\", \"Number of Articles\", \"Number of Funding Rounds\"]:\n",
        "    df_encoded[col] = pd.to_numeric(df_encoded[col], errors='coerce')\n",
        "\n",
        "# Identify categorical features\n",
        "cat_features = [col for col in features if df_encoded[col].dtype == 'object']\n",
        "\n",
        "# Prepare training data: remove rows where target is missing\n",
        "train_df = df_encoded.dropna(subset=features + [target_col])\n",
        "predict_df = df_encoded[df_encoded[target_col].isnull()]\n",
        "\n",
        "# Handle 'nan' values in categorical features for encoding\n",
        "for col in cat_features:\n",
        "    train_df.loc[:, col] = train_df[col].astype(str).fillna('Unknown')\n",
        "    predict_df.loc[:, col] = predict_df[col].astype(str).fillna('Unknown')\n",
        "\n",
        "# Use OrdinalEncoder to transform categorical features\n",
        "encoder = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
        "train_df.loc[:, cat_features] = encoder.fit_transform(train_df[cat_features])\n",
        "predict_df.loc[:, cat_features] = encoder.transform(predict_df[cat_features])\n",
        "\n",
        "# --- Train and Predict ---\n",
        "X_train = train_df[features]\n",
        "y_train = train_df[target_col]\n",
        "X_pred = predict_df[features]\n",
        "\n",
        "# Train a RandomForestRegressor model\n",
        "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict the missing values\n",
        "y_pred = model.predict(X_pred)\n",
        "\n",
        "# --- Impute and Save ---\n",
        "df_cleaned.loc[df_cleaned[target_col].isnull(), target_col] = np.round(y_pred)\n",
        "df_cleaned.to_csv('/content/Canada_cleaned.csv', index=False)\n",
        "\n",
        "print(f\"‚úÖ Missing after imputation for {target_col}: {df_cleaned[target_col].isnull().sum()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3xY6Pr5xYZc0",
        "outputId": "d5ddaa0c-4768-4787-9fa6-8b6e6349882a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Missing after imputation for Number of Events: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "import numpy as np\n",
        "\n",
        "# Load the cleaned data\n",
        "df_cleaned = pd.read_csv('/content/Canada_cleaned.csv')\n",
        "\n",
        "# --- Step A: Clean Valuation column ---\n",
        "target_col = \"Valuation at IPO\"\n",
        "df_cleaned[target_col] = pd.to_numeric(\n",
        "    df_cleaned[target_col].astype(str).str.replace(\",\", \"\"), errors='coerce'\n",
        ")\n",
        "\n",
        "# --- Step B: Focus only on IPO companies ---\n",
        "ipo_df = df_cleaned[df_cleaned[\"Funding Status\"] == \"IPO\"].copy()\n",
        "\n",
        "# --- Step C: Prepare Data and Features ---\n",
        "features = [\n",
        "    \"Total Funding Amount\",\n",
        "    \"Last Funding Amount\",\n",
        "    \"Estimated Revenue Range\",\n",
        "    \"CB Rank (Company)\",\n",
        "    \"Number of Employees\",\n",
        "    \"Industries\"\n",
        "]\n",
        "cat_features = [\"Estimated Revenue Range\", \"Industries\"]\n",
        "\n",
        "train_df = ipo_df.dropna(subset=features + [target_col])\n",
        "test_df = ipo_df[ipo_df[target_col].isnull()]\n",
        "\n",
        "if len(train_df) < 5:\n",
        "    print(\"‚ö†Ô∏è Not enough IPO rows with real valuations. Skipping imputation.\")\n",
        "elif test_df.empty:\n",
        "    print(f\"‚ÑπÔ∏è No missing values found for {target_col}. Nothing to predict.\")\n",
        "else:\n",
        "    # Handle NaNs in categorical features\n",
        "    for col in cat_features:\n",
        "        train_df.loc[:, col] = train_df[col].astype(str).fillna('Unknown')\n",
        "        test_df.loc[:, col] = test_df[col].astype(str).fillna('Unknown')\n",
        "\n",
        "    encoder = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
        "    train_df.loc[:, cat_features] = encoder.fit_transform(train_df[cat_features])\n",
        "    test_df.loc[:, cat_features] = encoder.transform(test_df[cat_features])\n",
        "\n",
        "    X_train = train_df[features]\n",
        "    y_train = train_df[target_col]\n",
        "    X_test = test_df[features]\n",
        "\n",
        "    # --- Step D: Train model ---\n",
        "    model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # --- Step E: Predict and insert ---\n",
        "    y_pred = model.predict(X_test)\n",
        "    df_cleaned.loc[test_df.index, target_col] = y_pred\n",
        "    print(f\"‚úÖ Imputed {len(test_df)} rows for {target_col}\")\n",
        "\n",
        "# Save file\n",
        "df_cleaned.to_csv('/content/Canada_cleaned.csv', index=False)\n",
        "print(f\"‚úÖ Missing after imputation for {target_col}: {df_cleaned[target_col].isnull().sum()}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nbi-X1PxYZac",
        "outputId": "ef2f8332-b42e-4ae0-f0cf-583305d39fba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚ö†Ô∏è Not enough IPO rows with real valuations. Skipping imputation.\n",
            "‚úÖ Missing after imputation for Valuation at IPO: 49\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cols_to_check = [\n",
        "    \"Price\",\n",
        "    \"Valuation at IPO\",\n",
        "    \"IPqwery - Patents Granted\",\n",
        "    \"G2 Stack - Total Products Active\"\n",
        "]\n",
        "\n",
        "for col in cols_to_check:\n",
        "    print(f\"\\n--- {col} ---\")\n",
        "    print(\"Unique count:\", df_cleaned[col].nunique(dropna=False))\n",
        "    print(\"Sample values:\")\n",
        "    print(df_cleaned[col].dropna().unique()[:20])  # first 20 unique non-null values\n",
        "\n"
      ],
      "metadata": {
        "id": "r82xHUS3Y66w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e46d5ba-3d55-442a-8416-0e2a3dadf005"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Price ---\n",
            "Unique count: 1\n",
            "Sample values:\n",
            "[]\n",
            "\n",
            "--- Valuation at IPO ---\n",
            "Unique count: 1\n",
            "Sample values:\n",
            "[]\n",
            "\n",
            "--- IPqwery - Patents Granted ---\n",
            "Unique count: 2\n",
            "Sample values:\n",
            "[0.]\n",
            "\n",
            "--- G2 Stack - Total Products Active ---\n",
            "Unique count: 11\n",
            "Sample values:\n",
            "[18.  6. 24. 25. 14. 11.  4. 29. 16. 17.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "import numpy as np\n",
        "\n",
        "# Load data\n",
        "df_cleaned = pd.read_csv('/content/Canada_cleaned.csv')\n",
        "\n",
        "# List of numeric target columns to impute\n",
        "target_cols = [\n",
        "    \"Price\",\n",
        "    \"Valuation at IPO\",\n",
        "    \"IPqwery - Patents Granted\",\n",
        "    \"G2 Stack - Total Products Active\"\n",
        "]\n",
        "\n",
        "# Features we can use for prediction (choose generic ones available for all rows)\n",
        "base_features = [\n",
        "    \"Total Funding Amount\",\n",
        "    \"Last Funding Amount\",\n",
        "    \"Estimated Revenue Range\",\n",
        "    \"CB Rank (Company)\",\n",
        "    \"Number of Employees\",\n",
        "    \"Industries\"\n",
        "]\n",
        "\n",
        "cat_features = [\"Estimated Revenue Range\", \"Industries\"]\n",
        "\n",
        "for target_col in target_cols:\n",
        "    print(f\"\\nüöÄ Processing {target_col} ...\")\n",
        "\n",
        "    # Step 1: Force numeric\n",
        "    df_cleaned[target_col] = pd.to_numeric(\n",
        "        df_cleaned[target_col].astype(str).str.replace(\",\", \"\").str.strip(),\n",
        "        errors='coerce'\n",
        "    )\n",
        "\n",
        "    # Step 2: Train/predict split\n",
        "    train_df = df_cleaned.dropna(subset=base_features + [target_col]).copy()\n",
        "    test_df = df_cleaned[df_cleaned[target_col].isnull()].copy()\n",
        "\n",
        "    if len(train_df) < 5:\n",
        "        print(f\"‚ö†Ô∏è Skipping {target_col} ‚Äî not enough rows to train ({len(train_df)} available).\")\n",
        "        continue\n",
        "\n",
        "    # Step 3: Handle categoricals\n",
        "    for col in cat_features:\n",
        "        train_df.loc[:, col] = train_df[col].astype(str).fillna(\"Unknown\")\n",
        "        test_df.loc[:, col] = test_df[col].astype(str).fillna(\"Unknown\")\n",
        "\n",
        "    encoder = OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=-1)\n",
        "    train_df.loc[:, cat_features] = encoder.fit_transform(train_df[cat_features])\n",
        "    test_df.loc[:, cat_features] = encoder.transform(test_df[cat_features])\n",
        "\n",
        "    # Step 4: Train model\n",
        "    X_train = train_df[base_features]\n",
        "    y_train = train_df[target_col]\n",
        "    X_test = test_df[base_features]\n",
        "\n",
        "    model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Step 5: Predict and insert\n",
        "    preds = model.predict(X_test)\n",
        "    df_cleaned.loc[test_df.index, target_col] = preds\n",
        "\n",
        "    print(f\"‚úÖ Missing after imputation for {target_col}: {df_cleaned[target_col].isnull().sum()}\")\n",
        "\n",
        "# Save results\n",
        "df_cleaned.to_csv(\"/content/Canada_cleaned.csv\", index=False)\n",
        "print(\"\\nüíæ All imputations complete and saved to /content/Canada_cleaned.csv\")\n"
      ],
      "metadata": {
        "id": "_E2aPIjhnrdL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5472f17-9b41-492c-8fad-eb1fd745d9a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üöÄ Processing Price ...\n",
            "‚ö†Ô∏è Skipping Price ‚Äî not enough rows to train (0 available).\n",
            "\n",
            "üöÄ Processing Valuation at IPO ...\n",
            "‚ö†Ô∏è Skipping Valuation at IPO ‚Äî not enough rows to train (0 available).\n",
            "\n",
            "üöÄ Processing IPqwery - Patents Granted ...\n",
            "‚ö†Ô∏è Skipping IPqwery - Patents Granted ‚Äî not enough rows to train (2 available).\n",
            "\n",
            "üöÄ Processing G2 Stack - Total Products Active ...\n",
            "‚úÖ Missing after imputation for G2 Stack - Total Products Active: 0\n",
            "\n",
            "üíæ All imputations complete and saved to /content/Canada_cleaned.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# üßº Check missing values count and percentage\n",
        "missing_info = (\n",
        "    df_cleaned.isnull().sum()\n",
        "    .to_frame(\"Missing Count\")\n",
        "    .assign(\n",
        "        Missing_Percentage=lambda x: (x[\"Missing Count\"] / len(df_cleaned)) * 100\n",
        "    )\n",
        "    .sort_values(by=\"Missing Count\", ascending=False)\n",
        ")\n",
        "\n",
        "# üñ®Ô∏è Show only columns with missing values\n",
        "missing_info = missing_info[missing_info[\"Missing Count\"] > 0]\n",
        "print(missing_info)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F5aXkdsibWoN",
        "outputId": "fac225c2-0302-47a3-edc0-1a745b4cd901"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                           Missing Count  Missing_Percentage\n",
            "Actively Hiring                       49          100.000000\n",
            "Number of Exits                       49          100.000000\n",
            "Valuation at IPO                      49          100.000000\n",
            "Price                                 49          100.000000\n",
            "IPqwery - Patents Granted             47           95.918367\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Replace 'your_file.csv' with the actual path to your CSV file\n",
        "file_path = '/content/Canada_cleaned.csv'\n",
        "\n",
        "# Read the CSV file into a pandas DataFrame\n",
        "try:\n",
        "    df = pd.read_csv(file_path)\n",
        "\n",
        "    # Print the column names\n",
        "    print(\"Column names in the CSV file:\")\n",
        "    for col in df.columns:\n",
        "        print(col)\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: The file '{file_path}' was not found.\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UAALGa83bXSi",
        "outputId": "d3eb42f8-7798-4243-f797-020f248d5748"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Column names in the CSV file:\n",
            "Founded Date\n",
            "Number of Founders\n",
            "Company Type\n",
            "Number of Employees\n",
            "Industries\n",
            "Headquarters Location\n",
            "Headquarters Regions\n",
            "Number of Investors\n",
            "Actively Hiring\n",
            "Number of Funding Rounds\n",
            "Last Funding Amount\n",
            "Funding Status\n",
            "Last Funding Type\n",
            "Estimated Revenue Range\n",
            "IPqwery - Patents Granted\n",
            "SEMrush - Monthly Visits\n",
            "SEMrush - Visit Duration\n",
            "SEMrush - Page Views / Visit\n",
            "SEMrush - Bounce Rate\n",
            "Number of Events\n",
            "BuiltWith - Active Tech Count\n",
            "G2 Stack - Total Products Active\n",
            "Number of Articles\n",
            "CB Rank (Company)\n",
            "Total Funding Amount\n",
            "Valuation at IPO\n",
            "Price\n",
            "Number of Exits\n",
            "Industry Groups\n",
            "Apptopia - Downloads Last 30 Days\n",
            "Apptopia - Number of Apps\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import pandas as pd\n",
        "\n",
        "# # Load cleaned CSV\n",
        "# file_path = '/content/Canada_cleaned.csv'\n",
        "# df = pd.read_csv(file_path)\n",
        "\n",
        "# # Columns to keep\n",
        "# columns_to_keep = [\n",
        "#     'Founded Date', 'Number of Founders', 'Number of Employees', 'Industries',\n",
        "#     'Headquarters Location', 'Headquarters Regions', 'Number of Investors',\n",
        "#     'Actively Hiring', 'Number of Funding Rounds', 'Last Funding Amount',\n",
        "#     'Funding Status', 'Last Funding Type', 'Estimated Revenue Range',\n",
        "#     'Number of Events', 'BuiltWith - Active Tech Count', 'Total Funding Amount'\n",
        "# ]\n",
        "\n",
        "# # Keep only the required columns\n",
        "# df = df[columns_to_keep]\n",
        "\n",
        "# # Save back to the same file\n",
        "# df.to_csv(file_path, index=False)\n",
        "\n",
        "# print(f\"‚úÖ File saved with only {len(columns_to_keep)} columns at {file_path}\")\n"
      ],
      "metadata": {
        "id": "g7Y16UAndlrl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# numeric_cols_to_round = [\n",
        "#         \"Number of Founders\", \"Number of Employees\", \"Number of Investors\",\n",
        "#         \"Number of Funding Rounds\", \"IPqwery - Patents Granted\",\n",
        "#         \"SEMrush - Monthly Visits\", \"SEMrush - Visit Duration\", \"SEMrush - Page Views / Visit\",\n",
        "#         \"SEMrush - Bounce Rate\", \"Number of Events\", \"BuiltWith - Active Tech Count\",\n",
        "#         \"G2 Stack - Total Products Active\", \"Number of Articles\",\n",
        "#         \"Number of Exits\", \"Apptopia - Downloads Last 30 Days\", \"Apptopia - Number of Apps\"\n",
        "#     ]\n",
        "\n",
        "# for col in numeric_cols_to_round:\n",
        "#     if col in df_cleaned.columns:\n",
        "#         # Check if the column is of a float type before rounding\n",
        "#         if pd.api.types.is_numeric_dtype(df_cleaned[col]):\n",
        "#             df_cleaned[col] = df_cleaned[col].round(0).astype('Int64')\n",
        "# print(\"‚úÖ Rounded specified numeric columns to the nearest whole number.\")"
      ],
      "metadata": {
        "id": "KS1kJMgOglBI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # üßº Check missing values count and percentage\n",
        "# missing_info = (\n",
        "#     df_cleaned.isnull().sum()\n",
        "#     .to_frame(\"Missing Count\")\n",
        "#     .assign(\n",
        "#         Missing_Percentage=lambda x: (x[\"Missing Count\"] / len(df_cleaned)) * 100\n",
        "#     )\n",
        "#     .sort_values(by=\"Missing Count\", ascending=False)\n",
        "# )\n",
        "\n",
        "# # üñ®Ô∏è Show only columns with missing values\n",
        "# missing_info = missing_info[missing_info[\"Missing Count\"] > 0]\n",
        "# print(missing_info)\n",
        "\n"
      ],
      "metadata": {
        "id": "DDRgzwPXhPbP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WuoId2Csn1_F"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}